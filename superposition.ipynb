{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superposition\n",
    "\n",
    "Last access (y.m.d): 19.09.06  \n",
    "Last update (y.m.d): 19.09.06  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'll look at truly testing the superposition aspect of the newer V1 experiments. In particular, for a given stimulus with dispersion > 1 (i.e. not just a single grating), the components of that stimulus will have been presented in isolation. This allows us to test $R_{1+2+..}$ against $R_1 + R_2 + ...$, where $_i$ are different stimulus components.\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "- Example cell or experiment\n",
    "   - suppression index (all conditions)  \n",
    "   - sf tuning predictions   \n",
    "   - rvc predictions  \n",
    "- All V1 data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg') # to avoid GUI/cluster issues...\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf as pltSave\n",
    "import matplotlib.animation as anim\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import helper_fcns as hf\n",
    "import autoreload\n",
    "import scipy.optimize as opt\n",
    "from scipy.stats.mstats import gmean as geomean\n",
    "\n",
    "import sys # so that we can import model_responses (in different folder)\n",
    "import model_responses\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('once');\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('https://raw.githubusercontent.com/paul-levy/SF_diversity/master/paul_plt_style.mplstyle');\n",
    "\n",
    "basePath = os.getcwd() + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before any plotting, fix plotting paramaters\n",
    "plt.style.use('https://raw.githubusercontent.com/paul-levy/SF_diversity/master/paul_plt_style.mplstyle');\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.size'] = 20;\n",
    "rcParams['pdf.fonttype'] = 42 # should be 42, but there are kerning issues                                                                                                                                                                                                    \n",
    "rcParams['ps.fonttype'] = 42 # should be 42, but there are kerning issues                                                                                                                                                                                                     \n",
    "\n",
    "rcParams['lines.linewidth'] = 2.5;\n",
    "rcParams['axes.linewidth'] = 1.5;\n",
    "rcParams['lines.markersize'] = 8; # this is in style sheet, just being explicit\n",
    "rcParams['lines.markeredgewidth'] = 0; # no edge, since weird tings happen then\n",
    "\n",
    "rcParams['xtick.major.size'] = 15\n",
    "rcParams['xtick.minor.size'] = 5; # no minor ticks\n",
    "rcParams['ytick.major.size'] = 15\n",
    "rcParams['ytick.minor.size'] = 0; # no minor ticks\n",
    "\n",
    "rcParams['xtick.major.width'] = 2\n",
    "rcParams['xtick.minor.width'] = 2;\n",
    "rcParams['ytick.major.width'] = 2\n",
    "rcParams['ytick.minor.width'] = 0\n",
    "\n",
    "rcParams['font.style'] = 'oblique';\n",
    "rcParams['font.size'] = 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example cell or experiment\n",
    "\n",
    "This section of code is used to look at just one cell or one experiment (e.g. all of V1_orig).\n",
    "\n",
    "In this section, I outline some of the key components of the analysis and make helpful visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit\n",
    "expDir   = 'V1/';\n",
    "dataListNm = hf.get_datalist(expDir);\n",
    "descrFits_f0 = 'descrFits_190503_sach_flex.npy';\n",
    "rvcName = 'rvcFits_190905' # updated - computes RVC for best responses (i.e. f0 or f1)\n",
    "rvcName = 'rvcFits_190828_f1'\n",
    "\n",
    "# expDir   = 'altExp/';\n",
    "# dataListNm = hf.get_datalist(expDir);\n",
    "# descrFits_f0 = 'descrFits_190503_poiss_flex.npy';\n",
    "# rvcName = None;\n",
    "# rvcnm = 'rvcFits_190905_pos.npy';\n",
    "# rvcName = 'rvcFits_190905_pos.npy';\n",
    "\n",
    "## now, let it run\n",
    "dataPath = basePath + expDir + 'structures/'\n",
    "save_loc = basePath + expDir + 'figures/'\n",
    "\n",
    "dataList = hf.np_smart_load(dataPath + dataListNm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlt=1;\n",
    "save_locSuper = save_loc + 'superposition/'\n",
    "if not os.path.exists(save_locSuper):\n",
    "    os.makedirs(save_locSuper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one cell?\n",
    "# cells = [5]; \n",
    "\n",
    "# or do all?\n",
    "cells = np.arange(1, 1+len(dataList['unitName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zr_rm = lambda x: x[x>0];\n",
    "# more flexible - only get values where x AND z are greater than some value \"gt\" (e.g. 0, 1, 0.4, ...)\n",
    "zr_rm_pair = lambda x, z, gt: [x[np.logical_and(x>gt, z>gt)], z[np.logical_and(x>gt, z>gt)]];\n",
    "# zr_rm_pair = lambda x, z: [x[np.logical_and(x>0, z>0)], z[np.logical_and(x>0, z>0)]] if np.logical_and(x!=[], z!=[])==True else [], [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we'll save measures we are going use for analysis purpose - e.g. supperssion index, c50\n",
    "suppr_cell = dict();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cells:\n",
    "    curr_suppr = dict();\n",
    "    try:\n",
    "        nRows, nCols = 3, 2;\n",
    "        \n",
    "        which_cell = i; # which cell - index will be which_cell - 1\n",
    "        cellName = dataList['unitName'][which_cell-1];\n",
    "        expInd = hf.get_exp_ind(dataPath, cellName)[0]\n",
    "        S = hf.np_smart_load(dataPath + cellName + '_sfm.npy')\n",
    "        expData = S['sfm']['exp']['trial'];\n",
    "        \n",
    "        # first, compute f1f0 ratio to determine if we look at f0 or f1 response\n",
    "        f1f0_rat = hf.compute_f1f0(expData, which_cell, expInd, dataPath, descrFitName_f0=descrFits_f0)[0];\n",
    "        curr_suppr['f1f0'] = f1f0_rat;\n",
    "        \n",
    "        if f1f0_rat > 1: # i.e. if we're looking at a simple cell, then let's get F1\n",
    "            if rvcName is not None:\n",
    "                rvcFits = hf.get_rvc_fits(dataPath, expInd, which_cell, rvcName=rvcName);\n",
    "            else:\n",
    "                rvcFits = None\n",
    "            spikes_byComp = hf.get_spikes(expData, get_f0=0, rvcFits=rvcFits, expInd=expInd);\n",
    "            spikes = np.array([np.sum(x) for x in spikes_byComp]);\n",
    "            rates = True; # when we get the spikes from rvcFits, they've already been converted into rates (in hf.get_all_fft)\n",
    "            baseline = None; # f1 has no \"DC\", yadig?\n",
    "        else: # otherwise, if it's complex, just get F0\n",
    "            spikes = hf.get_spikes(expData, get_f0=1, rvcFits=None, expInd=expInd);\n",
    "            rates = False; # get_spikes without rvcFits is directly from spikeCount, which is counts, not rates!\n",
    "            baseline = hf.blankResp(expData, expInd)[0]; # we'll plot the spontaneous rate\n",
    "            # why mult by stimDur? well, spikes are not rates but baseline is, so we convert baseline to count (i.e. not rate, too)\n",
    "            spikes = spikes - baseline*hf.get_exp_params(expInd).stimDur; \n",
    "            \n",
    "        _, _, respOrg, respAll = hf.organize_resp(spikes, expData, expInd);\n",
    "        resps, stimVals, val_con_by_disp, _, _ = hf.tabulate_responses(expData, expInd, overwriteSpikes=spikes, respsAsRates=rates);\n",
    "        predResps = resps[2];\n",
    "    \n",
    "        respMean = resps[0]; # equivalent to resps[0];\n",
    "        respStd = np.nanstd(respAll, -1); # take std of all responses for a given condition\n",
    "        # compute SEM, too\n",
    "        findNaN = np.isnan(respAll);\n",
    "        nonNaN  = np.sum(findNaN == False, axis=-1);\n",
    "        respSem = np.nanstd(respAll, -1) / np.sqrt(nonNaN);\n",
    "\n",
    "        ### organize stimulus information\n",
    "        all_disps = stimVals[0];\n",
    "        all_cons = stimVals[1];\n",
    "        all_sfs = stimVals[2];\n",
    "\n",
    "        nCons = len(all_cons);\n",
    "        nSfs = len(all_sfs);\n",
    "        nDisps = len(all_disps);\n",
    "\n",
    "        maxResp = np.maximum(np.nanmax(respMean), np.nanmax(predResps));\n",
    "        # by disp\n",
    "        clrs_d = cm.viridis(np.linspace(0,0.75,nDisps-1));\n",
    "        lbls_d = ['disp: %s' % str(x) for x in range(nDisps)];\n",
    "        # by sf\n",
    "        val_sfs = hf.get_valid_sfs(S, disp=1, con=val_con_by_disp[1][0], expInd=expInd) # pick \n",
    "        clrs_sf = cm.viridis(np.linspace(0,.75,len(val_sfs)));\n",
    "        lbls_sf = ['sf: %.2f' % all_sfs[x] for x in val_sfs];\n",
    "        # by con\n",
    "        val_con = all_cons;\n",
    "        clrs_con = cm.viridis(np.linspace(0,.75,len(val_con)));\n",
    "        lbls_con = ['con: %.2f' % x for x in val_con];\n",
    "\n",
    "        fSuper, ax = plt.subplots(nRows, nCols, figsize=(10*nCols, 8*nRows))\n",
    "        sns.despine(fig=fSuper, offset=10)\n",
    "        \n",
    "        allMix = [];\n",
    "        allSum = [];\n",
    "\n",
    "        ### plot reference tuning [row 1 (i.e. 2nd row)]\n",
    "        ## on the right, SF tuning (high contrast)\n",
    "        sfRef = hf.nan_rm(respMean[0, :, -1]); # high contrast tuning\n",
    "        ax[1, 1].plot(all_sfs, sfRef, 'k-', marker='o', label='ref. tuning (d0, high con)', clip_on=False)\n",
    "        ax[1, 1].set_xscale('log')\n",
    "        ax[1, 1].set_xlabel('sf (c/deg)')\n",
    "        ax[1, 1].set_ylabel('response (spikes/s)')\n",
    "        ax[1, 1].legend(fontsize='x-small');\n",
    "        ## then on the left, RVC (peak SF)\n",
    "        sfPeak = np.argmax(sfRef); # stupid/simple, but just get the rvc for the max response\n",
    "        v_cons_single = val_con_by_disp[0]\n",
    "        rvcRef = hf.nan_rm(respMean[0, sfPeak, v_cons_single]);\n",
    "        # now, if possible, let's also plot the RVC fit\n",
    "        if rvcName is not None:\n",
    "            rvcFits = hf.get_rvc_fits(dataPath, expInd, which_cell, rvcName=rvcName);\n",
    "            rel_rvc = rvcFits[0]['params'][sfPeak]; # we get 0 dispersion, peak SF\n",
    "#             rel_rvc = np.array([-15.        , 2.75*6.80224262, 0.3  ]);\n",
    "            rvc_mod = hf.get_rvc_model();\n",
    "            plt_cons = np.geomspace(all_cons[0], all_cons[-1], 50);\n",
    "            c50, pk = rel_rvc[-1], rvcFits[0]['conGain'][sfPeak];\n",
    "            ax[1, 0].plot(plt_cons, rvc_mod(*rel_rvc, plt_cons), 'k--', label='rvc fit (c50=%.2f, gain=%0f)' %(c50, pk))\n",
    "            # and save it\n",
    "            curr_suppr['c50'] = c50; curr_suppr['conGain'] = pk;\n",
    "\n",
    "        ax[1, 0].plot(all_cons[v_cons_single], rvcRef, 'k-', marker='o', label='ref. tuning (d0, peak SF)', clip_on=False)\n",
    "        ax[1, 0].set_xscale('log')\n",
    "        ax[1, 0].set_xlabel('contrast (%)');\n",
    "        ax[1, 0].set_ylabel('response (spikes/s)')\n",
    "        ax[1, 0].legend(fontsize='x-small');\n",
    "\n",
    "        for d in range(nDisps):\n",
    "            if d == 0: # we don't care about single gratings!\n",
    "                dispRats = [];\n",
    "                continue; \n",
    "            v_cons = np.array(val_con_by_disp[d]);\n",
    "            n_v_cons = len(v_cons);\n",
    "\n",
    "            # plot split out by each contrast [0,1]\n",
    "            for c in reversed(range(n_v_cons)):\n",
    "                v_sfs = hf.get_valid_sfs(S, d, v_cons[c], expInd)\n",
    "                for s in v_sfs:\n",
    "                    mixResp = respMean[d, s, v_cons[c]];\n",
    "                    allMix.append(mixResp);\n",
    "                    sumResp = predResps[d, s, v_cons[c]];\n",
    "                    allSum.append(sumResp);\n",
    "        #             print('condition: d(%d), c(%d), sf(%d):: pred(%.2f)|real(%.2f)' % (d, v_cons[c], s, sumResp, mixResp))\n",
    "                    # PLOT in by-disp panel\n",
    "                    if c == 0 and s == v_sfs[0]:\n",
    "                        ax[0, 0].plot(sumResp, mixResp, 'o', color=clrs_d[d-1], label=lbls_d[d], clip_on=False)\n",
    "                    else:\n",
    "                        ax[0, 0].plot(sumResp, mixResp, 'o', color=clrs_d[d-1], clip_on=False)\n",
    "                    # PLOT in by-sf panel\n",
    "                    sfInd = np.where(np.array(v_sfs) == s)[0][0]; # will only be one entry, so just \"unpack\"\n",
    "                    if d == 1 and c == 0:\n",
    "                        ax[0, 1].plot(sumResp, mixResp, 'o', color=clrs_sf[sfInd], label=lbls_sf[sfInd], clip_on=False);\n",
    "                    else:\n",
    "                        ax[0, 1].plot(sumResp, mixResp, 'o', color=clrs_sf[sfInd], clip_on=False);\n",
    "                    # plot baseline, if f0...\n",
    "#                     if baseline is not None:\n",
    "#                         [ax[0, i].axhline(baseline, linestyle='--', color='k', label='spon. rate') for i in range(2)];\n",
    "\n",
    "            # plot averaged across all cons/sfs (i.e. average for the whole dispersion) [1,0]\n",
    "            mixDisp = respMean[d, :, :].flatten();\n",
    "            sumDisp = predResps[d, :, :].flatten();\n",
    "            mixDisp, sumDisp = zr_rm_pair(mixDisp, sumDisp, 0.5);\n",
    "            curr_rat = np.mean(np.divide(mixDisp, sumDisp));\n",
    "#             curr_rat = geomean(np.divide(mixDisp, sumDisp));\n",
    "            ax[2, 0].bar(d, curr_rat, color=clrs_d[d-1]);\n",
    "            dispRats.append(curr_rat);\n",
    "#             ax[2, 0].bar(d, np.mean(np.divide(mixDisp, sumDisp)), color=clrs_d[d-1]);\n",
    "            if d == 1:\n",
    "                ax[2, 0].set_xlabel('dispersion');\n",
    "                ax[2, 0].set_ylabel('suppression ratio')\n",
    "                ax[2, 0].axhline(1, ls='--', color='k')\n",
    "        curr_suppr['supr_disp'] = dispRats;\n",
    "            \n",
    "        ### plot averaged across all cons/disps\n",
    "        sfInds = []; sfRats = [];\n",
    "        for s in range(len(val_sfs)):\n",
    "            try: # not all sfs will have legitmate values;\n",
    "                # only get mixtures (i.e. ignore single gratings)\n",
    "                mixSf = respMean[1:, val_sfs[s], :].flatten();\n",
    "                sumSf = predResps[1:, val_sfs[s], :].flatten();\n",
    "                mixSf, sumSf = zr_rm_pair(mixSf, sumSf, 0.5);\n",
    "                sfInds.append(s); sfRats.append(np.mean(np.divide(mixSf, sumSf)))\n",
    "#                 sfInds.append(s); sfRats.append(geomean(np.divide(mixSf, sumSf)))\n",
    "            except:\n",
    "                pass\n",
    "        # get the offset/scale of the ratio so that we can plot a rescaled/flipped version of\n",
    "        # the high con/single grat tuning for reference...does the suppression match the response?\n",
    "        offset, scale = np.nanmax(sfRats), np.nanmax(sfRats) - np.nanmin(sfRats);\n",
    "        sfRef = hf.nan_rm(respMean[0, val_sfs, -1]); # high contrast tuning\n",
    "        sfRefShift = offset - scale * (sfRef/np.max(sfRef))\n",
    "        ax[2,1].scatter(all_sfs[val_sfs][sfInds], sfRats, color=clrs_sf[sfInds], clip_on=False)\n",
    "        ax[2,1].plot(all_sfs[val_sfs][sfInds], sfRats, 'k-', clip_on=False, label='suppression tuning')\n",
    "        ax[2,1].plot(all_sfs[val_sfs], sfRefShift, 'k--', label='ref. tuning', clip_on=False)\n",
    "        ax[2,1].axhline(1, ls='--', color='k')\n",
    "        ax[2,1].set_xlabel('sf (cpd)')\n",
    "        ax[2,1].set_xscale('log')\n",
    "        ax[2,1].set_xlim((np.min(all_sfs), np.max(all_sfs)));\n",
    "        ax[2,1].set_ylabel('suppression ratio');\n",
    "        ax[2,1].legend(fontsize='x-small');\n",
    "        curr_suppr['supr_sf'] = sfRats;\n",
    "            \n",
    "        # make a polynomial fit\n",
    "        hmm = np.polyfit(allSum, allMix, deg=1) # returns [a, b] in ax + b \n",
    "        curr_suppr['supr_index'] = hmm[0];\n",
    "\n",
    "        suppr_cell[i] = curr_suppr;\n",
    "        \n",
    "        for j in range(1):\n",
    "            for jj in range(nCols):\n",
    "                ax[j, jj].axis('square')\n",
    "                ax[j, jj].set_xlabel('predicted');\n",
    "                ax[j, jj].set_ylabel('superposition');\n",
    "                ax[j, jj].plot([0, 1*maxResp], [0, 1*maxResp], 'k--')\n",
    "                ax[j, jj].set_xlim((-5, maxResp));\n",
    "                ax[j, jj].set_ylim((-5, 1.1*maxResp));\n",
    "                ax[j, jj].set_title('Suppression index: %.2f' % hmm[0])\n",
    "                ax[j, jj].legend(fontsize='x-small');\n",
    "\n",
    "        fSuper.suptitle('Superposition test: %d [%s; f1f0 %.2f]' % (which_cell, cellName, f1f0_rat))\n",
    "\n",
    "        if savePlt:\n",
    "            save_name = 'cell_%03d.pdf' % which_cell\n",
    "            pdfSv = pltSave.PdfPages(str(save_locSuper + save_name));\n",
    "            pdfSv.savefig(fSuper)\n",
    "            pdfSv.close();\n",
    "\n",
    "    except: # i.e. ignore this cell - some cells have improper data/expo files\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "For example, let's see if there's any correlation between suppression and the c50 or contrast gain of each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suppr_cell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0767a679d5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1f0s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1f0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc50s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c50'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconGain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conGain'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msupr_sfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'supr_sf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msupr_disps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'supr_disp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuppr_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'suppr_cell' is not defined"
     ]
    }
   ],
   "source": [
    "f1f0s = [suppr_cell[x]['f1f0'] for x in sorted(suppr_cell.keys())]\n",
    "c50s = [suppr_cell[x]['c50'] for x in sorted(suppr_cell.keys())]\n",
    "conGain = [suppr_cell[x]['conGain'] for x in sorted(suppr_cell.keys())]\n",
    "supr_sfs = [suppr_cell[x]['supr_sf'] for x in sorted(suppr_cell.keys())]\n",
    "supr_disps = [suppr_cell[x]['supr_disp'] for x in sorted(suppr_cell.keys())]\n",
    "supr_index = [suppr_cell[x]['supr_index'] for x in sorted(suppr_cell.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow, ncol = 3, 3;\n",
    "f, ax = plt.subplots(nrow, ncol, figsize=(12*ncol, 12*nrow))\n",
    "\n",
    "# c50 vs. suppression index\n",
    "ax[0, 0].plot(c50s, supr_index, 'o');\n",
    "ax[0, 0].set_xlabel('c50');\n",
    "ax[0, 0].set_ylabel('suppression index');\n",
    "ax[0, 0].set_xscale('log')\n",
    "\n",
    "# conGain vs. suppression index\n",
    "ax[1, 0].plot(conGain, supr_index, 'o');\n",
    "ax[1, 0].set_xlabel('con gain');\n",
    "ax[1, 0].set_ylabel('suppression index');\n",
    "ax[1, 0].set_xscale('log')\n",
    "\n",
    "# f1f0 vs. suppression index\n",
    "ax[2, 0].plot(f1f0s, supr_index, 'o');\n",
    "ax[2, 0].set_xlabel('f1f0 ratio');\n",
    "ax[2, 0].set_ylabel('suppression index');\n",
    "# ax[2, 0].set_xscale('log')\n",
    "\n",
    "# sfs, colored by c50\n",
    "c50_vals = np.log(c50s);\n",
    "c50_zto1 = 0.75*np.divide(c50_vals-np.min(c50_vals), np.max(c50_vals) - np.min(c50_vals));\n",
    "[ax[0, 1].semilogy(sfs, color=cm.gray(c50_z)) for sfs, c50_z in zip(supr_sfs, c50_zto1)];\n",
    "ax[0, 1].set_xlabel('sf index');\n",
    "ax[0, 1].set_ylabel('superposition ratio');\n",
    "# hacky, but do it fo rnow\n",
    "ax[0, 1].set_ylim([0.1, 10])\n",
    "minorticks = np.hstack((np.linspace(0.1, 1, 10), np.linspace(1, 10, 10)))\n",
    "ax[0, 1].yaxis.set_ticks(minorticks)\n",
    "# ax[, 1].set_yticks\n",
    "# ax[0, 1].yaxis.label(True, which='minor');\n",
    "ax[0, 1].set_title('lighter is higher c50');\n",
    "\n",
    "# sfs, colored by conGain\n",
    "cg = [x if type(x) == np.float64 else x[0] for x in conGain]; # strange packaging of some conGain values :: TODO - check why (problem should be in rvc_fit or in superposition above)\n",
    "gain_vals = np.log(cg);\n",
    "gain_zto1 = 0.75*np.divide(gain_vals-np.min(gain_vals), np.max(gain_vals) - np.min(gain_vals));\n",
    "[ax[1, 1].semilogy(sfs, color=cm.gray(gain_z)) for sfs, gain_z in zip(supr_sfs, gain_zto1)];\n",
    "ax[1, 1].set_xlabel('sf index');\n",
    "ax[1, 1].set_ylabel('superposition ratio');\n",
    "# hacky, but do it for now\n",
    "ax[1, 1].set_ylim([0.1, 10])\n",
    "minorticks = np.hstack((np.linspace(0.1, 1, 10), np.linspace(1, 10, 10)))\n",
    "ax[1, 1].yaxis.set_ticks(minorticks)\n",
    "# ax[1, 1].yaxis.label(True, which='minor')\n",
    "ax[1, 1].set_title('lighter is higher con gain')\n",
    "\n",
    "# sfs, colored by f1f0\n",
    "cg = [x if type(x) == np.float64 else x[0] for x in conGain]; # strange packaging of some conGain values :: TODO - check why (problem should be in rvc_fit or in superposition above)\n",
    "f1f0_vals = f1f0s; # no need to log\n",
    "f1f0_zto1 = 0.75*np.divide(f1f0_vals-np.min(f1f0_vals), np.max(f1f0_vals) - np.min(f1f0_vals));\n",
    "[ax[2, 1].semilogy(sfs, color=cm.gray(f1f0_z)) for sfs, f1f0_z in zip(supr_sfs, f1f0_zto1)];\n",
    "ax[2, 1].set_xlabel('sf index');\n",
    "ax[2, 1].set_ylabel('superposition ratio');\n",
    "# hacky, but do it for now\n",
    "ax[2, 1].set_ylim([0.1, 10])\n",
    "minorticks = np.hstack((np.linspace(0.1, 1, 10), np.linspace(1, 10, 10)))\n",
    "ax[2, 1].yaxis.set_ticks(minorticks)\n",
    "# ax[2, 1].yaxis.label(True, which='minor')\n",
    "ax[2, 1].set_title('lighter is higher f1f0')\n",
    "\n",
    "# disp, colored by c50\n",
    "c50_vals = np.log(c50s);\n",
    "c50_zto1 = 0.75*np.divide(c50_vals-np.min(c50_vals), np.max(c50_vals) - np.min(c50_vals));\n",
    "[ax[0, 2].semilogy(dsp, color=cm.gray(c50_z)) for dsp, c50_z in zip(supr_disps, c50_zto1)];\n",
    "ax[0, 2].set_xlabel('dispersion index');\n",
    "ax[0, 2].set_ylabel('superposition ratio');\n",
    "# ax[0, 2].set_ylim([0.25, 4])\n",
    "# ax[0, 2].set_yscale('log');\n",
    "# ax[0, 2].set_ylim([0.25, 4]);\n",
    "ax[0, 2].set_title('lighter is higher c50');\n",
    "\n",
    "# disp, colored by conGain\n",
    "cg = [x if type(x) == np.float64 else x[0] for x in conGain]; # strange packaging of some conGain values :: TODO - check why (problem should be in rvc_fit or in superposition above)\n",
    "gain_vals = np.log(cg);\n",
    "gain_zto1 = 0.75*np.divide(gain_vals-np.min(gain_vals), np.max(gain_vals) - np.min(gain_vals));\n",
    "[ax[1, 2].semilogy(dsp, color=cm.gray(gain_z)) for dsp, gain_z in zip(supr_disps, gain_zto1)];\n",
    "ax[1, 2].set_xlabel('dispersion index');\n",
    "ax[1, 2].set_ylabel('superposition ratio');\n",
    "# ax[1, 2].set_ylim([0.2, 5])\n",
    "ax[1, 2].set_title('lighter is higher con gain')\n",
    "\n",
    "# disp, colored by conGain\n",
    "cg = [x if type(x) == np.float64 else x[0] for x in conGain]; # strange packaging of some conGain values :: TODO - check why (problem should be in rvc_fit or in superposition above)\n",
    "f1f0_vals = f1f0s; # no need to log these values\n",
    "f1f0_zto1 = 0.75*np.divide(f1f0_vals-np.min(f1f0_vals), np.max(f1f0_vals) - np.min(f1f0_vals));\n",
    "[ax[2, 2].semilogy(dsp, color=cm.gray(f1f0_z)) for dsp, f1f0_z in zip(supr_disps, f1f0_zto1)];\n",
    "ax[2, 2].set_xlabel('dispersion index');\n",
    "ax[2, 2].set_ylabel('superposition ratio');\n",
    "# ax[2, 2].set_ylim([0.2, 5])\n",
    "ax[2, 2].set_title('lighter is higher f1f0')\n",
    "\n",
    "f.suptitle('Looking into superposition')\n",
    "\n",
    "sns.despine(offset=10);\n",
    "\n",
    "if savePlt:\n",
    "    save_name = 'superposition_corr.pdf' % which_cell\n",
    "    pdfSv = pltSave.PdfPages(str(save_locSuper + save_name));\n",
    "    pdfSv.savefig(f)\n",
    "    pdfSv.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted SF tuning\n",
    "\n",
    "Now, let's get a sense for how the single gratings predict spatial frequency tuning to mixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit\n",
    "expDir   = 'V1/';\n",
    "dataListNm = hf.get_datalist(expDir);\n",
    "descrFits_f0 = 'descrFits_190503_sach_flex.npy';\n",
    "rvcName = 'rvcFits_190828_f1'\n",
    "\n",
    "# expDir   = 'altExp/';\n",
    "# dataListNm = hf.get_datalist(expDir);\n",
    "# descrFits_f0 = 'descrFits_190503_poiss_flex.npy';\n",
    "# rvcName = None\n",
    "\n",
    "## now, let it run\n",
    "dataPath = basePath + expDir + 'structures/'\n",
    "save_loc = basePath + expDir + 'figures/'\n",
    "\n",
    "dataList = hf.np_smart_load(dataPath + dataListNm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlt=1;\n",
    "save_locTune = save_loc + 'superposition/tuning_sf/'\n",
    "if not os.path.exists(save_locTune):\n",
    "    os.makedirs(save_locTune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one cell?\n",
    "# cells = [3]; \n",
    "\n",
    "# or do all?\n",
    "cells = np.arange(1, 1+len(dataList['unitName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up colors, labels                                                                                                                                                            \n",
    "predClr = 'r';\n",
    "predTxt = 'prediction';\n",
    "dataClr = 'k';\n",
    "dataTxt = 'data';\n",
    "diffClr = 'b';\n",
    "diffTxt = 'resp - pred';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cells:\n",
    "\n",
    "    try: # might have some bad cells, so we just continue/skip in that case\n",
    "        ####\n",
    "        ## gather information\n",
    "        ####\n",
    "        which_cell = i; # which cell - index will be which_cell - 1\n",
    "        cellName = dataList['unitName'][which_cell-1];\n",
    "        expInd = hf.get_exp_ind(dataPath, cellName)[0]\n",
    "        S = hf.np_smart_load(dataPath + cellName + '_sfm.npy')\n",
    "        expData = S['sfm']['exp']['trial'];\n",
    "\n",
    "        # first, compute f1f0 ratio to determine if we look at f0 or f1 response\n",
    "        f1f0_rat = hf.compute_f1f0(expData, which_cell, expInd, dataPath, descrFitName_f0=descrFits_f0)[0];\n",
    "\n",
    "        if f1f0_rat > 1: # i.e. if we're looking at a simple cell, then let's get F1\n",
    "            if rvcName is not None:\n",
    "                rvcFits = hf.get_rvc_fits(dataPath, expInd, which_cell, rvcName=rvcName);\n",
    "            else:\n",
    "                rvcFits = None\n",
    "            spikes_byComp = hf.get_spikes(expData, get_f0=0, rvcFits=rvcFits, expInd=expInd);\n",
    "            spikes = np.array([np.sum(x) for x in spikes_byComp]);\n",
    "            rates = True; # when we get the spikes from rvcFits, they've already been converted into rates (in hf.get_all_fft)\n",
    "            baseline = None; # f1 has no \"DC\", yadig?\n",
    "        else: # otherwise, if it's complex, just get F0 - and baseline subtract!\n",
    "            spikes = hf.get_spikes(expData, get_f0=1, rvcFits=None, expInd=expInd);\n",
    "            rates = False; # get_spikes without rvcFits is directly from spikeCount, which is counts, not rates!\n",
    "            baseline = hf.blankResp(expData, expInd)[0]; # we'll plot the spontaneous rate\n",
    "            spikes = spikes - baseline*hf.get_exp_params(expInd).stimDur; # why mult by stimDur? well, spikes are not rates but baseline is, so we convert baseline to count (i.e. not rate, too)\n",
    "            \n",
    "        _, _, respOrg, respAll = hf.organize_resp(spikes, expData, expInd);\n",
    "        resps, stimVals, val_con_by_disp, validByStimVal, _ = hf.tabulate_responses(expData, expInd, overwriteSpikes=spikes, respsAsRates=rates);\n",
    "\n",
    "        # get response mean/s.e.m.\n",
    "        respMean = resps[0]; # could be resps[0], too...\n",
    "        findNaN = np.isnan(respAll);\n",
    "        nonNaN  = np.sum(findNaN == False, axis=-1);\n",
    "        respSem = np.nanstd(respAll, -1) / np.sqrt(nonNaN);\n",
    "        # and prediction mean/\n",
    "        predResps = resps[2];\n",
    "        predStd   = resps[3];\n",
    "\n",
    "        ### organize stimulus information\n",
    "        all_disps = stimVals[0];\n",
    "        all_cons = stimVals[1];\n",
    "        all_sfs = stimVals[2];\n",
    "\n",
    "        nCons = len(all_cons);\n",
    "        nSfs = len(all_sfs);\n",
    "        nDisps = len(all_disps);\n",
    "\n",
    "        ####\n",
    "        ## now we plot\n",
    "        ####\n",
    "        fDisp = []; dispAx = [];\n",
    "\n",
    "        sfs_plot = np.logspace(np.log10(all_sfs[0]), np.log10(all_sfs[-1]), 100);\n",
    "\n",
    "        mixDisps = all_disps[all_disps>1]\n",
    "\n",
    "        for d, d_val in enumerate(mixDisps):\n",
    "\n",
    "            d_ind = d+1;\n",
    "            v_cons = val_con_by_disp[d_ind];\n",
    "            n_v_cons = len(v_cons);\n",
    "\n",
    "            nPanels = 2;\n",
    "            fCurr, dispCurr = plt.subplots(n_v_cons, nPanels, figsize=(nPanels*10, n_v_cons*6), sharey=False);\n",
    "#             fCurr, dispCurr = plt.subplots(n_v_cons, nPanels, figsize=(nPanels*12, n_v_cons*8), sharey=False);\n",
    "            fDisp.append(fCurr)\n",
    "            dispAx.append(dispCurr);\n",
    "\n",
    "            fCurr.suptitle('Superposition tuning: %d [%s; f1f0 %.2f]' % (which_cell, cellName, f1f0_rat))\n",
    "\n",
    "            maxResp = np.max(np.max(respMean[d_ind, ~np.isnan(respMean[d_ind, :, :])]));\n",
    "            maxPred = np.max(np.max(predResps[d_ind, ~np.isnan(predResps[d_ind, :, :])]));\n",
    "            maxPlot = np.maximum(maxResp, maxPred);\n",
    "\n",
    "            for c in reversed(range(n_v_cons)):\n",
    "                c_plt_ind = len(v_cons) - c - 1;\n",
    "                v_sfs = hf.get_valid_sfs(expData, d_ind, v_cons[c], expInd, stimVals, validByStimVal)\n",
    "\n",
    "                curr_sfs  = all_sfs[v_sfs];\n",
    "                curr_resp = respMean[d_ind, v_sfs, v_cons[c]]; # data response                                                                               \n",
    "                curr_pred = predResps[d_ind, v_sfs, v_cons[c]]; # predicted response                                                                            \n",
    "\n",
    "                ### LEFT SIDE: data versus prediction\n",
    "                ## plot data                                                                                                                                                               \n",
    "                dispAx[d][c_plt_ind, 0].errorbar(curr_sfs, curr_resp,\n",
    "                                                 respSem[d_ind, v_sfs, v_cons[c]], color=dataClr, fmt='-o', clip_on=False, label=dataTxt);\n",
    "        #         dispAx[d][c_plt_ind].axhline(blankMean, color=dataClr, linestyle='dashed', label='spon. rate');\n",
    "                # and baseline if applicable\n",
    "                if baseline is not None:\n",
    "#                     dispAx[d][c_plt_ind, 0].axhline(baseline, linestyle='--', color='k', label='spon. rate')\n",
    "                    dispAx[d][c_plt_ind, 0].set_ylabel('resp abv baseline (spikes/s)', fontsize='x-small');\n",
    "                else:\n",
    "                    dispAx[d][c_plt_ind, 0].set_ylabel('resp (spikes/s)', fontsize='x-small');\n",
    "\n",
    "                ## plot prediction\n",
    "                dispAx[d][c_plt_ind, 0].plot(curr_sfs, curr_pred, linestyle='-', marker='o', alpha=0.7, color=predClr, clip_on=False, label=predTxt);\n",
    "        #         dispAx[d][c_plt_ind, 0].errorbar(curr_sfs, curr_pred, predStd[d_ind, v_sfs, v_cons[c]], fmt='-o', alpha=0.7, color=predClr, clip_on=False, label=predTxt);\n",
    "        #         dispAx[d][c_plt_ind].axhline(modSponRate, color=modClr, linestyle='dashed')\n",
    "\n",
    "                ## labels\n",
    "                dispAx[d][c_plt_ind, 0].set_ylim((0, 1.1*maxPlot));\n",
    "                dispAx[d][c_plt_ind, 0].set_ylabel('resp (spikes/s)', fontsize='x-small');\n",
    "\n",
    "                ### RIGHT SIDE: difference plot\n",
    "                ## plot difference\n",
    "                curr_diff = curr_resp - curr_pred;\n",
    "                dispAx[d][c_plt_ind, 1].plot(curr_sfs, curr_diff, ls='-', marker='o', color=diffClr, label=diffTxt)\n",
    "                # and \"no effect\" line\n",
    "                dispAx[d][c_plt_ind, 1].axhline(0, linestyle='--', color='k', label='pred. match')\n",
    "\n",
    "                ## and the tuning curve for single gratings at high contrast\n",
    "                # ...does the superposition failure match the response?\n",
    "                # TODO: make reference curve not just high contrast?\n",
    "                sfRef = hf.nan_rm(respMean[0, :, -1]); # high contrast tuning\n",
    "                dispAx[d][c_plt_ind, 1].plot(all_sfs, sfRef, 'k-', label='ref. tuning (d0, high con)', clip_on=False)\n",
    "\n",
    "                ## labels\n",
    "                dispAx[d][c_plt_ind, 1].set_ylabel('resp difference (spikes/)', fontsize='x-small');\n",
    "\n",
    "                # Set ticks out, remove top/right axis, put ticks only on bottom/left\n",
    "                for i in range(nPanels):\n",
    "                    dispAx[d][c_plt_ind, i].legend(fontsize='xx-small'); # set up legend\n",
    "\n",
    "                    dispAx[d][c_plt_ind, i].set_xlim((min(all_sfs), max(all_sfs)));\n",
    "                    dispAx[d][c_plt_ind, i].set_xscale('log');\n",
    "                    if c == 0: # i.e. only the last c_plt_ind\n",
    "                        dispAx[d][c_plt_ind, i].set_xlabel('sf (c/deg)', fontsize='x-small');\n",
    "\n",
    "                    dispAx[d][c_plt_ind, i].set_title('D%02d: contrast: %.3f' % (d_ind, all_cons[v_cons[c]]), fontsize='small');\n",
    "\n",
    "                    dispAx[d][c_plt_ind, i].tick_params(labelsize=15, width=1, length=8, direction='out');\n",
    "                    dispAx[d][c_plt_ind, i].tick_params(width=1, length=4, which='minor', direction='out'); # minor ticks, too...                                                            \n",
    "                    sns.despine(ax=dispAx[d][c_plt_ind, i], offset=10, trim=False);\n",
    "    \n",
    "        if savePlt:\n",
    "            save_name = 'cell_%03d.pdf' % which_cell\n",
    "            pdfSv = pltSave.PdfPages(str(save_locTune + save_name));\n",
    "            for f in fDisp:\n",
    "                pdfSv.savefig(f)\n",
    "                plt.close(f)\n",
    "            pdfSv.close();\n",
    "\n",
    "    except: # i.e. ignore this cell - some cells have improper data/expo files\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted RVC\n",
    "\n",
    "Now, let's get a sense for how the single gratings predict response versus contrast to mixture stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit\n",
    "expDir   = 'V1/';\n",
    "dataListNm = hf.get_datalist(expDir);\n",
    "descrFits_f0 = 'descrFits_190503_sach_flex.npy';\n",
    "rvcName = 'rvcFits_190828_f1'\n",
    "\n",
    "# expDir   = 'altExp/';\n",
    "# dataListNm = hf.get_datalist(expDir);\n",
    "# descrFits_f0 = 'descrFits_190503_poiss_flex.npy';\n",
    "# rvcName = None\n",
    "\n",
    "## now, let it run\n",
    "dataPath = basePath + expDir + 'structures/'\n",
    "save_loc = basePath + expDir + 'figures/'\n",
    "\n",
    "dataList = hf.np_smart_load(dataPath + dataListNm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlt=1;\n",
    "save_locTune = save_loc + 'superposition_f0/tuning_rvc/'\n",
    "if not os.path.exists(save_locTune):\n",
    "    os.makedirs(save_locTune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up colors, labels                                                                                                                                                            \n",
    "predClr = 'r';\n",
    "predTxt = 'prediction';\n",
    "dataClr = 'k';\n",
    "dataTxt = 'data';\n",
    "diffClr = 'b';\n",
    "diffTxt = 'resp - pred';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one cell?\n",
    "# cells = [3]; \n",
    "\n",
    "# or do all?\n",
    "cells = np.arange(1, 1+len(dataList['unitName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cells:\n",
    "\n",
    "    try: # might have some bad cells, so we just continue/skip in that case\n",
    "        ####\n",
    "        ## gather information\n",
    "        ####\n",
    "        which_cell = i; # which cell - index will be which_cell - 1\n",
    "        cellName = dataList['unitName'][which_cell-1];\n",
    "        expInd = hf.get_exp_ind(dataPath, cellName)[0]\n",
    "        S = hf.np_smart_load(dataPath + cellName + '_sfm.npy')\n",
    "        expData = S['sfm']['exp']['trial'];\n",
    "\n",
    "        # first, compute f1f0 ratio to determine if we look at f0 or f1 response\n",
    "        f1f0_rat = hf.compute_f1f0(expData, which_cell, expInd, dataPath, descrFitName_f0=descrFits_f0)[0];\n",
    "\n",
    "        if f1f0_rat > 1e3: # i.e. if we're looking at a simple cell, then let's get F1\n",
    "            if rvcName is not None:\n",
    "                rvcFits = hf.get_rvc_fits(dataPath, expInd, which_cell, rvcName=rvcName);\n",
    "            else:\n",
    "                rvcFits = None\n",
    "            spikes_byComp = hf.get_spikes(expData, get_f0=0, rvcFits=rvcFits, expInd=expInd);\n",
    "            spikes = np.array([np.sum(x) for x in spikes_byComp]);\n",
    "            rates = True; # when we get the spikes from rvcFits, they've already been converted into rates (in hf.get_all_fft)\n",
    "            baseline = None; # f1 has no \"DC\", yadig?\n",
    "        else: # otherwise, if it's complex, just get F0\n",
    "            spikes = hf.get_spikes(expData, get_f0=1, rvcFits=None, expInd=expInd);\n",
    "            rates = False; # get_spikes without rvcFits is directly from spikeCount, which is counts, not rates!\n",
    "            baseline = hf.blankResp(expData, expInd)[0]; # we'll plot the spontaneous rate\n",
    "            # why mult by stimDur below? well, spikes are not rates but baseline is, so we convert baseline to count (i.e. not rate, too)\n",
    "            spikes = spikes - baseline*hf.get_exp_params(expInd).stimDur;\n",
    "\n",
    "        _, _, respOrg, respAll = hf.organize_resp(spikes, expData, expInd);\n",
    "        resps, stimVals, val_con_by_disp, validByStimVal, _ = hf.tabulate_responses(expData, expInd, overwriteSpikes=spikes, respsAsRates=rates);\n",
    "\n",
    "        # get response mean/s.e.m.\n",
    "        respMean = resps[0]; # could be resps[0], too...\n",
    "        findNaN = np.isnan(respAll);\n",
    "        nonNaN  = np.sum(findNaN == False, axis=-1);\n",
    "        respSem = np.nanstd(respAll, -1) / np.sqrt(nonNaN);\n",
    "        # and prediction mean/\n",
    "        predResps = resps[2];\n",
    "        predStd   = resps[3];\n",
    "\n",
    "        ### organize stimulus information\n",
    "        all_disps = stimVals[0];\n",
    "        all_cons = stimVals[1];\n",
    "        all_sfs = stimVals[2];\n",
    "\n",
    "        nCons = len(all_cons);\n",
    "        nSfs = len(all_sfs);\n",
    "        nDisps = len(all_disps);\n",
    "\n",
    "        ####\n",
    "        ## now we plot\n",
    "        ####\n",
    "        fDisp = []; dispAx = [];\n",
    "\n",
    "        sfs_plot = np.logspace(np.log10(all_sfs[0]), np.log10(all_sfs[-1]), 100);\n",
    "\n",
    "        mixDisps = all_disps[all_disps>1]\n",
    "\n",
    "        for d, d_val in enumerate(mixDisps):\n",
    "\n",
    "            d_ind = d+1;\n",
    "\n",
    "            v_sf_inds = hf.get_valid_sfs(expData, d_ind, val_con_by_disp[d_ind][0], expInd, stimVals, validByStimVal);\n",
    "            n_v_sfs = len(v_sf_inds);\n",
    "\n",
    "            nPanels = 2;\n",
    "            fCurr, dispCurr = plt.subplots(n_v_sfs, nPanels, figsize=(nPanels*12, n_v_sfs*8), sharey=False);\n",
    "            fDisp.append(fCurr)\n",
    "            dispAx.append(dispCurr);\n",
    "\n",
    "            fCurr.suptitle('Superposition RVC: %d [%s; f1f0 %.2f]' % (which_cell, cellName, f1f0_rat))\n",
    "\n",
    "            maxResp = np.max(np.max(respMean[d_ind, ~np.isnan(respMean[d_ind, :, :])]));\n",
    "            maxPred = np.max(np.max(predResps[d_ind, ~np.isnan(predResps[d_ind, :, :])]));\n",
    "            maxPlot = np.maximum(maxResp, maxPred);\n",
    "\n",
    "            for sf_ind_curr, sf_ind_total in enumerate(v_sf_inds):\n",
    "                v_cons = val_con_by_disp[d_ind];\n",
    "                curr_cons = all_cons[v_cons];\n",
    "\n",
    "                curr_resp = respMean[d_ind, sf_ind_total, v_cons]; # data response                                                                               \n",
    "                curr_pred = predResps[d_ind, sf_ind_total, v_cons]; # predicted response                                                                            \n",
    "\n",
    "                ### LEFT SIDE: data versus prediction\n",
    "                ## plot data                                                                                                                                                               \n",
    "                dispAx[d][sf_ind_curr, 0].errorbar(curr_cons, curr_resp,\n",
    "                                                 respSem[d_ind, sf_ind_total, v_cons], color=dataClr, fmt='-o', clip_on=False, label=dataTxt);\n",
    "        #         dispAx[d][c_plt_ind].axhline(blankMean, color=dataClr, linestyle='dashed', label='spon. rate');\n",
    "                # and baseline if applicable\n",
    "                if baseline is not None:\n",
    "#                     dispAx[d][c_plt_ind, 0].axhline(baseline, linestyle='--', color='k', label='spon. rate')\n",
    "                    dispAx[d][sf_ind_curr, 0].set_ylabel('resp abv baseline (spikes/s)', fontsize='x-small');\n",
    "                else:\n",
    "                    dispAx[d][sf_ind_curr, 0].set_ylabel('resp (spikes/s)', fontsize='x-small');\n",
    "\n",
    "                ## plot prediction\n",
    "                dispAx[d][sf_ind_curr, 0].plot(curr_cons, curr_pred, linestyle='-', marker='o', alpha=0.7, color=predClr, clip_on=False, label=predTxt);\n",
    "        #         dispAx[d][sf_ind_curr, 0].errorbar(curr_sfs, curr_pred, predStd[d_ind, v_sfs, v_cons[c]], fmt='-o', alpha=0.7, color=predClr, clip_on=False, label=predTxt);\n",
    "        #         dispAx[d][sf_ind_curr].axhline(modSponRate, color=modClr, linestyle='dashed')\n",
    "\n",
    "                ## labels, lims\n",
    "                dispAx[d][sf_ind_curr, 0].set_ylim((0, 1.1*maxPlot));\n",
    "                dispAx[d][sf_ind_curr, 0].set_ylabel('resp (spikes/s)', fontsize='x-small');\n",
    "                dispAx[d][sf_ind_curr, 0].set_xlim((0.3, np.max(all_cons)));\n",
    "\n",
    "                ### RIGHT SIDE: difference plot\n",
    "                ## plot difference\n",
    "                curr_diff = curr_resp - curr_pred;\n",
    "                dispAx[d][sf_ind_curr, 1].plot(curr_cons, curr_diff, ls='-', marker='o', color=diffClr, label=diffTxt)\n",
    "                # and \"no effect\" line\n",
    "                dispAx[d][sf_ind_curr, 1].axhline(0, linestyle='--', color='k', label='pred. match')\n",
    "\n",
    "                ## and then the tuning curve for single gratings at high contrast\n",
    "                # ...does the superposition failure match the response?\n",
    "                # TODO: make reference curve not just high contrast?\n",
    "                sfRef = hf.nan_rm(respMean[0, :, -1]); # high contrast tuning\n",
    "                sfPeak = np.argmax(sfRef); # stupid/simple, but just get the rvc for the max response\n",
    "                v_cons_single = val_con_by_disp[0]\n",
    "                rvcRef = hf.nan_rm(respMean[0, sfPeak, v_cons_single]);\n",
    "                dispAx[d][sf_ind_curr, 1].plot(all_cons[v_cons_single], rvcRef, 'k-', label='ref. tuning (d0, peak SF)', clip_on=False)\n",
    "                dispAx[d][sf_ind_curr, 1].set_xlim((np.min(all_cons), np.max(all_cons)));\n",
    "\n",
    "                ## labels\n",
    "                dispAx[d][sf_ind_curr, 1].set_ylabel('resp difference (spikes/)', fontsize='x-small');\n",
    "\n",
    "                # Set ticks out, remove top/right axis, put ticks only on bottom/left\n",
    "                for i in range(nPanels):\n",
    "                    dispAx[d][sf_ind_curr, i].legend(fontsize='xx-small'); # set up legend\n",
    "\n",
    "#                     dispAx[d][sf_ind_curr, i].set_xlim((min(curr_cons), max(curr_cons)));\n",
    "                    dispAx[d][sf_ind_curr, i].set_xscale('log');\n",
    "                    if c == 0: # i.e. only the last c_plt_ind\n",
    "                        dispAx[d][sf_ind_curr, i].set_xlabel('contrast (%)', fontsize='x-small');\n",
    "\n",
    "                    dispAx[d][sf_ind_curr, i].set_title('D%02d: sf: %.2f' % (d_ind, all_sfs[sf_ind_total]), fontsize='small');\n",
    "\n",
    "                    dispAx[d][sf_ind_curr, i].tick_params(labelsize=15, width=1, length=8, direction='out');\n",
    "                    dispAx[d][sf_ind_curr, i].tick_params(width=1, length=4, which='minor', direction='out'); # minor ticks, too...                                                            \n",
    "                    sns.despine(ax=dispAx[d][sf_ind_curr, i], offset=10, trim=False);\n",
    "    \n",
    "        if savePlt:\n",
    "            save_name = 'cell_%03d.pdf' % which_cell\n",
    "            pdfSv = pltSave.PdfPages(str(save_locTune + save_name));\n",
    "            for f in fDisp:\n",
    "                pdfSv.savefig(f)\n",
    "                plt.close(f)\n",
    "            pdfSv.close();\n",
    "\n",
    "    except: # i.e. ignore this cell - some cells have improper data/expo files\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full analysis\n",
    "\n",
    "Here, we'll try to further develop superposition analysis for all possible cells. Importantly, we can only analyze altExp/ and V1/ experiments (i.e. not V1_orig/) due to the needed construction of the stimulus set. Recall that the superposition analysis seeks to predict the response to mixture stimuli from the responses to constituent gratings when presented alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's gather the same pred/mix responses for all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppInds = [];\n",
    "for nm, ind in zip(dataList['unitName'], range(len(dataList['unitName']))):\n",
    "    \n",
    "    try:\n",
    "        # load cell\n",
    "        expInd = hf.get_exp_ind(dataPath, nm)[0]\n",
    "        S = hf.np_smart_load(dataPath + nm + '_sfm.npy')\n",
    "        expData = S['sfm']['exp']['trial'];\n",
    "    except:\n",
    "        continue;\n",
    "    \n",
    "    ### organize responses\n",
    "    resps, stimVals, val_con_by_disp, _, _ = hf.tabulate_responses(expData, expInd);\n",
    "    ### WARNING: WARNING: resps is WITHOUT any rvcAdjustment\n",
    "    predResps = resps[2];\n",
    "    rvcFits = hf.get_rvc_fits(dataPath, expInd, ind, rvcName='None');\n",
    "    spikes  = hf.get_spikes(expData, rvcFits=rvcFits, expInd=expInd);\n",
    "    _, _, respOrg, respAll    = hf.organize_resp(spikes, expData, expInd);\n",
    "\n",
    "    respMean = respOrg;\n",
    "    respStd = np.nanstd(respAll, -1); # take std of all responses for a given condition                                                                                                                         \n",
    "    # compute SEM, too                                                                                                                                                                                          \n",
    "    findNaN = np.isnan(respAll);\n",
    "    nonNaN  = np.sum(findNaN == False, axis=-1);\n",
    "    respSem = np.nanstd(respAll, -1) / np.sqrt(nonNaN);\n",
    "\n",
    "    ### organize stimulus information\n",
    "    all_disps, all_cons, all_sfs = stimVals[0:3];\n",
    "    nCons, nSfs, nDisps = len(all_cons), len(all_sfs), len(all_disps);\n",
    "    \n",
    "    allMix = [];\n",
    "    allSum = [];\n",
    "\n",
    "    for d in range(nDisps):\n",
    "        if d == 0: # we don't care about single gratings!\n",
    "            continue; \n",
    "        v_cons = np.array(val_con_by_disp[d]);\n",
    "        n_v_cons = len(v_cons);\n",
    "\n",
    "        for c in reversed(range(n_v_cons)):\n",
    "            v_sfs = hf.get_valid_sfs(S, d, v_cons[c], expInd)\n",
    "            for s in v_sfs:\n",
    "                mixResp = respMean[d, s, v_cons[c]];\n",
    "                allMix.append(mixResp);\n",
    "                sumResp = predResps[d, s, v_cons[c]];\n",
    "                allSum.append(sumResp);\n",
    "    \n",
    "    hmm = np.polyfit(allSum, allMix, deg=1) # returns [a, b] in ax + b \n",
    "    suppInds.append(hmm[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra/old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## DO YOU WANT TO RUN THIS?\n",
    "## DEBUGGING new changes in tabulate_responses --- works!\n",
    "################\n",
    "resps_GT, stimVals_GT, val_con_by_disp_GT, _, _ = hf.tabulate_responses(expData, expInd);\n",
    "resps_F0, stimVals_F0, val_con_by_disp_F0, _, _ = hf.tabulate_responses(expData, expInd, overwriteSpikes=expData['spikeCount']);\n",
    "f1_sum = np.array([np.sum(x)for x in expData['f1']]);\n",
    "resps_F1, stimVals_F1, val_con_by_disp_F1, _, _ = hf.tabulate_responses(expData, expInd, overwriteSpikes=f1_sum);\n",
    "f1_sum_adj = spikes\n",
    "resps_F1_adj, stimVals_F1_adj, val_con_by_disp_F1_adj, _, _ = hf.tabulate_responses(expData, expInd, overwriteSpikes=f1_sum_adj);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
