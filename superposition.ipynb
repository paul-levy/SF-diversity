{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'll look at truly testing the superposition aspect of the newer V1 experiments. In particular, for a given stimulus with dispersion > 1 (i.e. not just a single grating), the components of that stimulus will have been presented in isolation. This allows us to test $R_{1+2+..}$ against $R_1 + R_2 + ...$, where $_i$ are different stimulus components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg') # to avoid GUI/cluster issues...\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf as pltSave\n",
    "import matplotlib.animation as anim\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import helper_fcns as hf\n",
    "import autoreload\n",
    "import scipy.optimize as opt\n",
    "from scipy.stats.mstats import gmean as geomean\n",
    "\n",
    "import sys # so that we can import model_responses (in different folder)\n",
    "import model_responses\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('once');\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('https://raw.githubusercontent.com/paul-levy/SF_diversity/master/paul_plt_style.mplstyle');\n",
    "\n",
    "basePath = os.getcwd() + '/'\n",
    "\n",
    "## edit\n",
    "expDir   = 'V1/';\n",
    "dataListNm = 'dataList_glx.npy'\n",
    "\n",
    "## now, let it run\n",
    "dataPath = basePath + expDir + 'structures/'\n",
    "save_loc = basePath + expDir + 'figures/'\n",
    "\n",
    "dataList = hf.np_smart_load(dataPath + dataListNm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_cell = 7; # which cell - index will be which_cell - 1\n",
    "cellName = dataList['unitName'][which_cell-1];\n",
    "expInd = hf.get_exp_ind(dataPath, cellName)[0]\n",
    "S = hf.np_smart_load(dataPath + cellName + '_sfm.npy')\n",
    "expData = S['sfm']['exp']['trial'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### organize responses\n",
    "resps, stimVals, val_con_by_disp, _, _ = hf.tabulate_responses(expData, expInd);\n",
    "### WARNING: WARNING: resps is WITHOUT any rvcAdjustment\n",
    "predResps = resps[2];\n",
    "rvcFits = hf.get_rvc_fits(dataPath, expInd, which_cell, rvcName='None');\n",
    "spikes  = hf.get_spikes(expData, rvcFits=rvcFits, expInd=expInd);\n",
    "_, _, respOrg, respAll    = hf.organize_resp(spikes, expData, expInd);\n",
    "\n",
    "respMean = respOrg;\n",
    "respStd = np.nanstd(respAll, -1); # take std of all responses for a given condition\n",
    "# compute SEM, too\n",
    "findNaN = np.isnan(respAll);\n",
    "nonNaN  = np.sum(findNaN == False, axis=-1);\n",
    "respSem = np.nanstd(respAll, -1) / np.sqrt(nonNaN);\n",
    "\n",
    "### organize stimulus information\n",
    "all_disps = stimVals[0];\n",
    "all_cons = stimVals[1];\n",
    "all_sfs = stimVals[2];\n",
    "\n",
    "nCons = len(all_cons);\n",
    "nSfs = len(all_sfs);\n",
    "nDisps = len(all_disps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxResp = np.maximum(np.nanmax(respMean), np.nanmax(predResps));\n",
    "# by disp\n",
    "clrs_d = cm.viridis(np.linspace(0,1,nDisps-1));\n",
    "lbls_d = ['disp: %s' % str(x) for x in range(nDisps)];\n",
    "# by sf\n",
    "val_sfs = hf.get_valid_sfs(S, d=1, val_con_by_disp[1][0]) # pick \n",
    "clrs_d = cm.viridis(np.linspace(0,1,nDisps-1));\n",
    "lbls_d = ['disp: %s' % str(x) for x in range(nDisps)];\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(25, 10))\n",
    "\n",
    "allMix = [];\n",
    "allSum = [];\n",
    "\n",
    "for d in range(nDisps):\n",
    "    if d == 0: # we don't care about single gratings!\n",
    "        continue; \n",
    "    v_cons = np.array(val_con_by_disp[d]);\n",
    "    n_v_cons = len(v_cons);\n",
    "\n",
    "    for c in reversed(range(n_v_cons)):\n",
    "        v_sfs = hf.get_valid_sfs(S, d, v_cons[c], expInd)\n",
    "        for s in v_sfs:\n",
    "            mixResp = respMean[d, s, v_cons[c]];\n",
    "            allMix.append(mixResp);\n",
    "            sumResp = predResps[d, s, v_cons[c]];\n",
    "            allSum.append(sumResp);\n",
    "#             print('condition: d(%d), c(%d), sf(%d):: pred(%.2f)|real(%.2f)' % (d, v_cons[c], s, sumResp, mixResp))\n",
    "            if c == 0 and s == v_sfs[0]:\n",
    "                ax[0].plot(sumResp, mixResp, 'o', color=clrs_d[d-1], label=lbls_d[d])\n",
    "            else:\n",
    "                ax[0].plot(sumResp, mixResp, 'o', color=clrs_d[d-1])\n",
    "   \n",
    "# make a polynomial fit\n",
    "hmm = np.polyfit(allSum, allMix, deg=1) # returns [a, b] in ax + b \n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].axis('equal')\n",
    "    ax[i].set_xlabel('predicted');\n",
    "    ax[i].set_ylabel('superposition');\n",
    "    ax[i].plot([0, 1.2*maxResp], [0, 1.2*maxResp], 'k--')\n",
    "    ax[i].set_title('Suppression index: %.2f' % hmm[0])\n",
    "    ax[i].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's gather the same pred/mix responses for all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arc/2.2/p1/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/helper_fcns.py:1493: UserWarning: This experiment type (expInd=3) usually has associated RVC fits for resposne adjustment\n",
      "  warnings.warn('This experiment type (expInd=3) usually has associated RVC fits for resposne adjustment');\n",
      "/arc/2.2/p1/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/helper_fcns.py:1462: RuntimeWarning: Mean of empty slice\n",
      "  rateSfMix = numpy.nanmean(allSfMix, -1);\n",
      "/users/plevy/.conda/envs/lcv-python/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1628: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "suppInds = [];\n",
    "for nm, ind in zip(dataList['unitName'], range(len(dataList['unitName']))):\n",
    "    \n",
    "    try:\n",
    "        # load cell\n",
    "        expInd = hf.get_exp_ind(dataPath, nm)[0]\n",
    "        S = hf.np_smart_load(dataPath + nm + '_sfm.npy')\n",
    "        expData = S['sfm']['exp']['trial'];\n",
    "    except:\n",
    "        continue;\n",
    "    \n",
    "    ### organize responses\n",
    "    resps, stimVals, val_con_by_disp, _, _ = hf.tabulate_responses(expData, expInd);\n",
    "    ### WARNING: WARNING: resps is WITHOUT any rvcAdjustment\n",
    "    predResps = resps[2];\n",
    "    rvcFits = hf.get_rvc_fits(dataPath, expInd, ind, rvcName='None');\n",
    "    spikes  = hf.get_spikes(expData, rvcFits=rvcFits, expInd=expInd);\n",
    "    _, _, respOrg, respAll    = hf.organize_resp(spikes, expData, expInd);\n",
    "\n",
    "    respMean = respOrg;\n",
    "    respStd = np.nanstd(respAll, -1); # take std of all responses for a given condition                                                                                                                         \n",
    "    # compute SEM, too                                                                                                                                                                                          \n",
    "    findNaN = np.isnan(respAll);\n",
    "    nonNaN  = np.sum(findNaN == False, axis=-1);\n",
    "    respSem = np.nanstd(respAll, -1) / np.sqrt(nonNaN);\n",
    "\n",
    "    ### organize stimulus information\n",
    "    all_disps, all_cons, all_sfs = stimVals[0:3];\n",
    "    nCons, nSfs, nDisps = len(all_cons), len(all_sfs), len(all_disps);\n",
    "    \n",
    "    allMix = [];\n",
    "    allSum = [];\n",
    "\n",
    "    for d in range(nDisps):\n",
    "        if d == 0: # we don't care about single gratings!\n",
    "            continue; \n",
    "        v_cons = np.array(val_con_by_disp[d]);\n",
    "        n_v_cons = len(v_cons);\n",
    "\n",
    "        for c in reversed(range(n_v_cons)):\n",
    "            v_sfs = hf.get_valid_sfs(S, d, v_cons[c], expInd)\n",
    "            for s in v_sfs:\n",
    "                mixResp = respMean[d, s, v_cons[c]];\n",
    "                allMix.append(mixResp);\n",
    "                sumResp = predResps[d, s, v_cons[c]];\n",
    "                allSum.append(sumResp);\n",
    "    \n",
    "    hmm = np.polyfit(allSum, allMix, deg=1) # returns [a, b] in ax + b \n",
    "    suppInds.append(hmm[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
