{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sfMix reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this notebook to help read in sfMix experiments and manage the MountainSort spikes\n",
    "\n",
    "Last change: 22.02.22   \n",
    "Last opened: 22.02.22  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import helper_fcns as hf\n",
    "sys.path.insert(0, 'ExpoAnalysisTools/python/')\n",
    "from ExpoAnalysisTools.python import read_sfMix, readBasicCharacterization\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGN\n",
    "\n",
    "#### For the LGN, we'll also need to take into account the classification (i.e. Magno/Parvo/Other). We can use Manu's excel sheet to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    r22#5\n",
       "18    r32#5\n",
       "19    r33#5\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basePath = os.getcwd() + '/'\n",
    "sheetName = 'manu-classification-220222.xlsx';\n",
    "# sheetName = 'manu-classification.xlsx'; # original\n",
    "# There are 3 sheets - m675, m680, m682\n",
    "readIn = pd.read_excel(basePath + 'LGN/experiments/' + sheetName, sheet_name=['m675', 'm680', 'm682'])\n",
    "def idToStr(typeId):\n",
    "    if int(typeId) == 0:\n",
    "        return 'parvo';\n",
    "    elif int(typeId) == 1:\n",
    "        return 'magno';\n",
    "    else:\n",
    "        return 'tbd'; # i.e. Manu says he couldn't classify definitively\n",
    "    \n",
    "readInFlat = pd.concat(readIn, keys=['m675', 'm680', 'm682']).reset_index()\n",
    "# rename some things\n",
    "readInFlat.rename(columns={'level_0': 'm#', 'level_1': 'expCount',\n",
    "                          'celllabel': 'label', 'cellno': 'cellNum',\n",
    "                          'expono': 'progNum'}, inplace=True)\n",
    "\n",
    "# Are there NaN types?\n",
    "nans = np.where(np.isnan(readInFlat['type']))[0]\n",
    "readInFlat['label'][nans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually edit the NaN types...\n",
    "readInFlat.at[12, 'type'] = 0 # parvo, per notes\n",
    "readInFlat.at[18, 'type'] = 2 # TBD, per notes\n",
    "readInFlat.at[19, 'type'] = 2 # TBD, per notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index into a string with the type\n",
    "readInFlat['typeStr'] = readInFlat['type'].apply(idToStr)\n",
    "readInFlat['fullName'] = ['%s%s' % (x,y) for x,y in zip(readInFlat['m#'], readInFlat['label'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a dataframe with the eccentricity and type for each recorded LGN cell. We can use this in the creation of the datalist to ensure that each cell has an associated eccentricity and type that will carry through all of the analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the .xml to .npy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "il.reload(read_sfMix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing LGN/recordings/m675r04#4[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r04_sfm.npy\n",
      "Analyzing LGN/recordings/m675r06#6[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r06_sfm.npy\n",
      "Analyzing LGN/recordings/m675r08#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r08_sfm.npy\n",
      "Analyzing LGN/recordings/m675r13#4[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r13_sfm.npy\n",
      "Analyzing LGN/recordings/m675r15#11[sfMixLGN].xml\n",
      "Analyzing LGN/recordings/m675r15#7[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r15_sfm.npy\n",
      "Analyzing LGN/recordings/m675r16#7[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r16_sfm.npy\n",
      "Analyzing LGN/recordings/m675r17#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r17_sfm.npy\n",
      "Analyzing LGN/recordings/m675r18#6[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r18_sfm.npy\n",
      "Analyzing LGN/recordings/m675r19#6[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r19_sfm.npy\n",
      "Analyzing LGN/recordings/m675r20#6[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r20_sfm.npy\n",
      "Analyzing LGN/recordings/m675r21#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r21_sfm.npy\n",
      "Analyzing LGN/recordings/m675r22#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r22_sfm.npy\n",
      "Analyzing LGN/recordings/m675r23#12[sfMixLGN].xml\n",
      "Analyzing LGN/recordings/m675r23#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r23_sfm.npy\n",
      "Analyzing LGN/recordings/m675r24#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r24_sfm.npy\n",
      "Analyzing LGN/recordings/m675r26#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r26_sfm.npy\n",
      "Analyzing LGN/recordings/m675r27#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r27_sfm.npy\n",
      "Analyzing LGN/recordings/m675r32#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r32_sfm.npy\n",
      "Analyzing LGN/recordings/m675r33#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r33_sfm.npy\n",
      "Analyzing LGN/recordings/m675r36#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r36_sfm.npy\n",
      "Analyzing LGN/recordings/m675r37#10[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r37_sfm.npy\n",
      "Analyzing LGN/recordings/m675r38#8[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r38_sfm.npy\n",
      "Analyzing LGN/recordings/m675r39#8[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r39_sfm.npy\n",
      "Analyzing LGN/recordings/m675r40#10[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r40_sfm.npy\n",
      "Analyzing LGN/recordings/m675r42#9[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r42_sfm.npy\n",
      "Analyzing LGN/recordings/m675r43#8[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r43_sfm.npy\n",
      "Analyzing LGN/recordings/m675r45#11[sfMixLGN].xml\n",
      "Analyzing LGN/recordings/m675r45#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r45_sfm.npy\n",
      "Analyzing LGN/recordings/m675r47#9[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r47_sfm.npy\n",
      "Analyzing LGN/recordings/m675r48#9[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r48_sfm.npy\n",
      "Analyzing LGN/recordings/m675r49#10[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r49_sfm.npy\n",
      "Analyzing LGN/recordings/m675r50#7[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r50_sfm.npy\n",
      "Analyzing LGN/recordings/m675r51#7[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r51_sfm.npy\n",
      "Analyzing LGN/recordings/m675r52#6[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r52_sfm.npy\n",
      "Analyzing LGN/recordings/m675r54#7[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r54_sfm.npy\n",
      "Analyzing LGN/recordings/m675r56#5[sfMixLGN].xml\n",
      "saving: LGN/structures/m675r56_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r03#5[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r03_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r04#5[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r04_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r05#4[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r05_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r06#4[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r06_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r07#5[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r07_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r09#6[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r09_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r10#10[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p01r10_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r12#11[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r12_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r13#7[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p01r13_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r14#5[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r14_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r16#6[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p01r16_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r17#10[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r17_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r18#10[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r18_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r19#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r19_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r20#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r20_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r21#11[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r21_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r22#11[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p01r22_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r23#6[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p01r23_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r25#12[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p01r25_sfm.npy\n",
      "Analyzing LGN/recordings/m680p01r26#6[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p01r26_sfm.npy\n",
      "Analyzing LGN/recordings/m680p02r30#12[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p02r30_sfm.npy\n",
      "Analyzing LGN/recordings/m680p02r32#10[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p02r32_sfm.npy\n",
      "Analyzing LGN/recordings/m680p02r35#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p02r35_sfm.npy\n",
      "Analyzing LGN/recordings/m680p02r37#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p02r37_sfm.npy\n",
      "Analyzing LGN/recordings/m680p02r38#12[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p02r38_sfm.npy\n",
      "Analyzing LGN/recordings/m680p02r39#6[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p02r39_sfm.npy\n",
      "Analyzing LGN/recordings/m680p03r44#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p03r44_sfm.npy\n",
      "Analyzing LGN/recordings/m680p03r55#12[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p03r55_sfm.npy\n",
      "Analyzing LGN/recordings/m680p03r56#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p03r56_sfm.npy\n",
      "Analyzing LGN/recordings/m680p07r63#8[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p07r63_sfm.npy\n",
      "Analyzing LGN/recordings/m680p07r64#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p07r64_sfm.npy\n",
      "Analyzing LGN/recordings/m680p07r66#11[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p07r66_sfm.npy\n",
      "Analyzing LGN/recordings/m680p07r67#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p07r67_sfm.npy\n",
      "Analyzing LGN/recordings/m680p07r68#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p07r68_sfm.npy\n",
      "Analyzing LGN/recordings/m680p08r72#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p08r72_sfm.npy\n",
      "Analyzing LGN/recordings/m680p08r73#11[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p08r73_sfm.npy\n",
      "Analyzing LGN/recordings/m680p08r75#7[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p08r75_sfm.npy\n",
      "Analyzing LGN/recordings/m680p08r77#11[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m680p08r77_sfm.npy\n",
      "Analyzing LGN/recordings/m680p10r81#9[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p10r81_sfm.npy\n",
      "Analyzing LGN/recordings/m680p10r83#6[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p10r83_sfm.npy\n",
      "Analyzing LGN/recordings/m680p10r84#12[sfMixLGNhalfInt].xml\n",
      "Analyzing LGN/recordings/m680p10r84#6[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p10r84_sfm.npy\n",
      "Analyzing LGN/recordings/m680p10r85#10[sfMixLGNhalfInt].xml\n",
      "saving: LGN/structures/m680p10r85_sfm.npy\n",
      "Analyzing LGN/recordings/m682r14#11[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m682r14_sfm.npy\n",
      "Analyzing LGN/recordings/m682r15#11[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m682r15_sfm.npy\n",
      "Analyzing LGN/recordings/m682r16#12[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m682r16_sfm.npy\n",
      "Analyzing LGN/recordings/m682r17#13[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m682r17_sfm.npy\n",
      "Analyzing LGN/recordings/m682r18#7[sfMixHalfInt].xml\n",
      "saving: LGN/structures/m682r18_sfm.npy\n"
     ]
    }
   ],
   "source": [
    "dl_name_read = 'dataList_210524.npy'\n",
    "dl_name_save = 'dataList_220222.npy'\n",
    "read_sfMix.read_sfMix_all('LGN/recordings/', dl_name=dl_name_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the dataList\n",
    "Remember that the previous function above creates/updates a dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataList\n",
    "dl = hf.np_smart_load('LGN/structures/%s' % dl_name_save)\n",
    "cellType = np.nan * np.zeros((len(dl['unitName'], )), dtype='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, go through and find (in the readInFlat dataframe) the corresponding cell type, if there\n",
    "for ii, nm in enumerate(dl['unitName']):\n",
    "    split = nm.split('l');\n",
    "    if len(split) == 1: # i.e. there was NOT an l in this name...\n",
    "        \n",
    "        mStr, unitNum = hf.parse_exp_name(nm)[0:2] # first two arguments\n",
    "        \n",
    "        validRow = np.where((readInFlat['m#'] == mStr) & (readInFlat['cellNum'] == unitNum))[0]\n",
    "        if len(validRow)>0:\n",
    "            cellType[ii] = readInFlat.at[validRow[0], 'typeStr']\n",
    "        else:\n",
    "            print('No match for %s' % nm)\n",
    "    \n",
    "\n",
    "dl['unitType'] = cellType\n",
    "np.save('LGN/structures/%s' % dl_name_save, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 parvo cells\n",
      "27 magno cells\n",
      "11 tbd cells\n"
     ]
    }
   ],
   "source": [
    "for nm in ['parvo', 'magno', 'tbd']:\n",
    "    ok = len(np.where(dl['unitType'] == nm)[0])\n",
    "    print('%d %s cells' % (ok, nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy over the basic program information from the reference file dataList (210524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = hf.np_smart_load('LGN/structures/%s' % dl_name_save)\n",
    "dl_og = hf.np_smart_load('LGN/structures/%s' % dl_name_read);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make sure all the names are aligned before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m675r04 -- m675r04',\n",
       " 'm675r06 -- m675r06',\n",
       " 'm675r08 -- m675r08',\n",
       " 'm675r13 -- m675r13',\n",
       " 'm675r15 -- m675r15',\n",
       " 'm675r16 -- m675r16',\n",
       " 'm675r17 -- m675r17',\n",
       " 'm675r18 -- m675r18',\n",
       " 'm675r19 -- m675r19',\n",
       " 'm675r20 -- m675r20',\n",
       " 'm675r21 -- m675r21',\n",
       " 'm675r22 -- m675r22',\n",
       " 'm675r23 -- m675r23',\n",
       " 'm675r24 -- m675r24',\n",
       " 'm675r26 -- m675r26',\n",
       " 'm675r27 -- m675r27',\n",
       " 'm675r32 -- m675r32',\n",
       " 'm675r33 -- m675r33',\n",
       " 'm675r36 -- m675r36',\n",
       " 'm675r37 -- m675r37',\n",
       " 'm675r38 -- m675r38',\n",
       " 'm675r39 -- m675r39',\n",
       " 'm675r40 -- m675r40',\n",
       " 'm675r42 -- m675r42',\n",
       " 'm675r43 -- m675r43',\n",
       " 'm675r45 -- m675r45',\n",
       " 'm675r47 -- m675r47',\n",
       " 'm675r48 -- m675r48',\n",
       " 'm675r49 -- m675r49',\n",
       " 'm675r50 -- m675r50',\n",
       " 'm675r51 -- m675r51',\n",
       " 'm675r52 -- m675r52',\n",
       " 'm675r54 -- m675r54',\n",
       " 'm675r56 -- m675r56',\n",
       " 'm680p01r03 -- m680p01r03',\n",
       " 'm680p01r04 -- m680p01r04',\n",
       " 'm680p01r05 -- m680p01r05',\n",
       " 'm680p01r06 -- m680p01r06',\n",
       " 'm680p01r07 -- m680p01r07',\n",
       " 'm680p01r09 -- m680p01r09',\n",
       " 'm680p01r10 -- m680p01r10',\n",
       " 'm680p01r12 -- m680p01r12',\n",
       " 'm680p01r13 -- m680p01r13',\n",
       " 'm680p01r14 -- m680p01r14',\n",
       " 'm680p01r16 -- m680p01r16',\n",
       " 'm680p01r17 -- m680p01r17',\n",
       " 'm680p01r18 -- m680p01r18',\n",
       " 'm680p01r19 -- m680p01r19',\n",
       " 'm680p01r20 -- m680p01r20',\n",
       " 'm680p01r21 -- m680p01r21',\n",
       " 'm680p01r22 -- m680p01r22',\n",
       " 'm680p01r23 -- m680p01r23',\n",
       " 'm680p01r25 -- m680p01r25',\n",
       " 'm680p01r26 -- m680p01r26',\n",
       " 'm680p02r30 -- m680p02r30',\n",
       " 'm680p02r32 -- m680p02r32',\n",
       " 'm680p02r35 -- m680p02r35',\n",
       " 'm680p02r37 -- m680p02r37',\n",
       " 'm680p02r38 -- m680p02r38',\n",
       " 'm680p02r39 -- m680p02r39',\n",
       " 'm680p03r44 -- m680p03r44',\n",
       " 'm680p03r55 -- m680p03r55',\n",
       " 'm680p03r56 -- m680p03r56',\n",
       " 'm680p07r63 -- m680p07r63',\n",
       " 'm680p07r64 -- m680p07r64',\n",
       " 'm680p07r66 -- m680p07r66',\n",
       " 'm680p07r67 -- m680p07r67',\n",
       " 'm680p07r68 -- m680p07r68',\n",
       " 'm680p08r72 -- m680p08r72',\n",
       " 'm680p08r73 -- m680p08r73',\n",
       " 'm680p08r75 -- m680p08r75',\n",
       " 'm680p08r77 -- m680p08r77',\n",
       " 'm680p10r81 -- m680p10r81',\n",
       " 'm680p10r83 -- m680p10r83',\n",
       " 'm680p10r84 -- m680p10r84',\n",
       " 'm680p10r85 -- m680p10r85',\n",
       " 'm682r14 -- m682r14',\n",
       " 'm682r15 -- m682r15',\n",
       " 'm682r16 -- m682r16',\n",
       " 'm682r17 -- m682r17',\n",
       " 'm682r18 -- m682r18']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['%s -- %s' % (x,y) for x,y in zip(dl['unitName'], dl_og['unitName'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl['basicProgName'] = dl_og['basicProgName']\n",
    "dl['basicProgOrder'] = dl_og['basicProgOrder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('LGN/structures/%s' % dl_name_save, dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "il.reload(read_sfMix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_name = 'dataList_210528.npy'\n",
    "# read_sfMix.read_sfMix_all('V1/recordings/', dl_name=dl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 cells\n"
     ]
    }
   ],
   "source": [
    "test_files = glob.glob('V1/structures/m*_sfm.npy')\n",
    "\n",
    "unitNames = [];\n",
    "expTypes = [];\n",
    "unitArea = [];\n",
    "\n",
    "for t in sorted(test_files):\n",
    "    \n",
    "    curr_file = hf.np_smart_load(t);\n",
    "    \n",
    "    unitNames.append(curr_file['unitLabel'])\n",
    "    expName = curr_file['sfm']['exp']['filename'];\n",
    "    expTypes.append(hf.parse_exp_name(expName)[-2]);\n",
    "    unitArea.append('V1')\n",
    "    \n",
    "dataList = dict();\n",
    "dataList['unitName'] = unitNames;\n",
    "dataList['expType'] = expTypes\n",
    "dataList['unitArea'] = unitArea;\n",
    "\n",
    "print('%d cells' % len(unitNames))\n",
    "\n",
    "np.save('V1/structures/%s' % dl_name, dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
