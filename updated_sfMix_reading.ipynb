{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sfMix reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this notebook to help read in sfMix experiments and manage the MountainSort spikes\n",
    "\n",
    "Last change: 21.05.29   \n",
    "Last opened: 21.05.29  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import helper_fcns as hf\n",
    "sys.path.insert(0, 'ExpoAnalysisTools/python/')\n",
    "from ExpoAnalysisTools.python import read_sfMix, readBasicCharacterization\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGN\n",
    "\n",
    "#### For the LGN, we'll also need to take into account the classification (i.e. Magno/Parvo/Other). We can use Manu's excel sheet to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.getcwd() + '/'\n",
    "sheetName = 'manu-classification.xlsx';\n",
    "# There are 3 sheets - m675, m680, m682\n",
    "readIn = pd.read_excel(basePath + 'LGN/experiments/' + sheetName, sheet_name=['m675', 'm680', 'm682'])\n",
    "def idToStr(typeId):\n",
    "    if int(typeId) == 0:\n",
    "        return 'parvo';\n",
    "    elif int(typeId) == 1:\n",
    "        return 'magno';\n",
    "    else:\n",
    "        return 'tbd'; # i.e. Manu says he couldn't classify definitively\n",
    "    \n",
    "readInFlat = pd.concat(readIn, keys=['m675', 'm680', 'm682']).reset_index()\n",
    "# rename some things\n",
    "readInFlat.rename(columns={'level_0': 'm#', 'level_1': 'expCount',\n",
    "                          'celllabel': 'label', 'cellno': 'cellNum',\n",
    "                          'expono': 'progNum'}, inplace=True)\n",
    "\n",
    "# Are there NaN types?\n",
    "nans = np.where(np.isnan(readInFlat['type']))[0]\n",
    "readInFlat['label'][nans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually edit the NaN types...\n",
    "readInFlat.at[12, 'type'] = 0 # parvo, per notes\n",
    "readInFlat.at[18, 'type'] = 2 # TBD, per notes\n",
    "readInFlat.at[19, 'type'] = 2 # TBD, per notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the index into a string with the type\n",
    "readInFlat['typeStr'] = readInFlat['type'].apply(idToStr)\n",
    "readInFlat['fullName'] = ['%s%s' % (x,y) for x,y in zip(readInFlat['m#'], readInFlat['label'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a dataframe with the eccentricity and type for each recorded LGN cell. We can use this in the creation of the datalist to ensure that each cell has an associated eccentricity and type that will carry through all of the analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the .xml to .npy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il.reload(read_sfMix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_name = 'dataList_210524.npy'\n",
    "read_sfMix.read_sfMix_all('LGN/recordings/', dl_name=dl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the dataList\n",
    "Remember that the previous function above creates/updates a dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-3252d0b0ea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the dataList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LGN/structures/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdl_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcellType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unitName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# load the dataList\n",
    "dl = hf.np_smart_load('LGN/structures/%s' % dl_name)\n",
    "cellType = np.nan * np.zeros((len(dl['unitName'], )), dtype='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, go through and find (in the readInFlat dataframe) the corresponding cell type, if there\n",
    "for ii, nm in enumerate(dl['unitName']):\n",
    "    split = nm.split('l');\n",
    "    if len(split) == 1: # i.e. there was NOT an l in this name...\n",
    "        \n",
    "        mStr, unitNum = hf.parse_exp_name(nm)[0:2] # first two arguments\n",
    "        \n",
    "        validRow = np.where((readInFlat['m#'] == mStr) & (readInFlat['cellNum'] == unitNum))[0]\n",
    "        if len(validRow)>0:\n",
    "            cellType[ii] = readInFlat.at[validRow[0], 'typeStr']\n",
    "        else:\n",
    "            print('No match for %s' % nm)\n",
    "    \n",
    "\n",
    "dl['unitType'] = cellType\n",
    "np.save('LGN/structures/%s' % dl_name, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nm in ['parvo', 'magno', 'tbd']:\n",
    "    ok = len(np.where(dl['unitType'] == nm)[0])\n",
    "    print('%d %s cells' % (ok, nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "il.reload(read_sfMix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_name = 'dataList_210528.npy'\n",
    "# read_sfMix.read_sfMix_all('V1/recordings/', dl_name=dl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 cells\n"
     ]
    }
   ],
   "source": [
    "test_files = glob.glob('V1/structures/m*_sfm.npy')\n",
    "\n",
    "unitNames = [];\n",
    "expTypes = [];\n",
    "unitArea = [];\n",
    "\n",
    "for t in sorted(test_files):\n",
    "    \n",
    "    curr_file = hf.np_smart_load(t);\n",
    "    \n",
    "    unitNames.append(curr_file['unitLabel'])\n",
    "    expName = curr_file['sfm']['exp']['filename'];\n",
    "    expTypes.append(hf.parse_exp_name(expName)[-2]);\n",
    "    unitArea.append('V1')\n",
    "    \n",
    "dataList = dict();\n",
    "dataList['unitName'] = unitNames;\n",
    "dataList['expType'] = expTypes\n",
    "dataList['unitArea'] = unitArea;\n",
    "\n",
    "print('%d cells' % len(unitNames))\n",
    "\n",
    "np.save('V1/structures/%s' % dl_name, dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
