{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting matlab data into python\n",
    "\n",
    "Last update (ymd): 19.10.22  \n",
    "Last access (ymd): 19.11.05   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this Jupyter notebook to convert Expo data from .mat to .npy files, and to make adjustments to existing .npy files (e.g. renaming fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, os\n",
    "import sys\n",
    "sys.path.insert(0, 'functions/'); # add this path for makeStimulus\n",
    "import makeStimulus\n",
    "import helper_fcns as hf\n",
    "import autoreload\n",
    "\n",
    "import pdb\n",
    "\n",
    "# constants - directories\n",
    "base_loc = '/arc/2.2/p1/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/';\n",
    "# base_loc = '/users/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/';\n",
    "\n",
    "loc_matData = 'V1/structures/'; # where are the .mat files? say \"recordings\" if re-naming the original matlab files\n",
    "loc_pyData = 'V1/structures/'; # where do you want the .npy files?\n",
    "\n",
    "recArea = 'V1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The original conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the .mat files to convert; then, convert unless already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(loc_matData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['._sfMixAlt.exxp',\n",
       " '._sfMixFlexTf.exxp',\n",
       " '._sfMixHalfInt.exxp',\n",
       " '._sfMixInt.exxp',\n",
       " 'm676l01#109[sfMixLGN].exxd',\n",
       " 'm676l01#109[sfMixLGN].xml',\n",
       " 'm676l01#95[sfMixLGN].exxd',\n",
       " 'm676l01#95[sfMixLGN].xml',\n",
       " 'm676p3l06#13[sfMixHalfInt].exxd',\n",
       " 'm676p3l06#13[sfMixHalfInt].xml',\n",
       " 'm676p3l07#15[sfMixInt].exxd',\n",
       " 'm676p3l07#15[sfMixInt].xml',\n",
       " 'm676p3l11#16[sfMixHalfInt].exxd',\n",
       " 'm676p3l11#16[sfMixHalfInt].xml',\n",
       " 'm676p3l13#26[sfMixHalfInt].exxd',\n",
       " 'm676p3l13#26[sfMixHalfInt].xml',\n",
       " 'm676p3l15#7[sfMixHalfInt].exxd',\n",
       " 'm676p3l15#7[sfMixHalfInt].xml',\n",
       " 'm678p5l06#15[sfMixHalfInt].exxd',\n",
       " 'm678p5l06#15[sfMixHalfInt].xml',\n",
       " 'm678p5l06#7[sfMixHalfInt].exxd',\n",
       " 'm678p5l06#7[sfMixHalfInt].xml',\n",
       " 'm678p5l07#9[sfMixHalfInt].exxd',\n",
       " 'm678p5l07#9[sfMixHalfInt].xml',\n",
       " 'm678p6l11#9[sfMixHalfInt].exxd',\n",
       " 'm678p6l11#9[sfMixHalfInt].xml',\n",
       " 'm678p6l12#12[sfMixHalfInt].exxd',\n",
       " 'm678p6l12#12[sfMixHalfInt].xml',\n",
       " 'm678p6l15#11[sfMixHalfInt].exxd',\n",
       " 'm678p6l15#11[sfMixHalfInt].xml',\n",
       " 'm678p6l16#9[sfMixHalfInt].exxd',\n",
       " 'm678p6l16#9[sfMixHalfInt].xml',\n",
       " 'm678p6l17#6[sfMixHalfInt].exxd',\n",
       " 'm678p6l17#6[sfMixHalfInt].xml',\n",
       " 'm678p6l18#6[sfMixHalfInt].exxd',\n",
       " 'm678p6l18#6[sfMixHalfInt].xml',\n",
       " 'm678p7r03#8[sfMixHalfInt].exxd',\n",
       " 'm678p7r03#8[sfMixHalfInt].xml',\n",
       " 'm681p02r11#10[sfMixHalfInt].xml',\n",
       " 'm681p02r2#8[sfMixHalfInt].xml',\n",
       " 'm681p02r3#8[sfMixHalfInt].xml',\n",
       " 'm681p02r4#8[sfMixHalfInt].xml',\n",
       " 'm681p02r5#8[sfMixHalfInt].xml',\n",
       " 'm681p02r6#13[sfMixHalfInt].xml',\n",
       " 'm681p02r7#11[sfMixHalfInt].xml',\n",
       " 'm681p02r7#7[sfMixHalfInt].xml',\n",
       " 'm681p02r8#9[sfMixHalfInt].xml',\n",
       " 'm681p02r9#21[sfMixHalfInt].xml',\n",
       " 'm681p03r5#7[sfMixHalfInt].xml',\n",
       " 'm681p04r19#8[sfMixHalfInt].xml',\n",
       " 'm681p04r20#9[sfMixHalfInt].xml',\n",
       " 'm681p04r22#8[sfMixHalfInt].xml',\n",
       " 'm681p04r24#11[sfMixHalfInt].xml',\n",
       " 'm681p04r25#11[sfMixHalfInt].xml',\n",
       " 'm681p04r26#7[sfMixHalfInt].xml',\n",
       " 'm681p04r27#9[sfMixHalfInt].xml',\n",
       " 'm681p04r29#8[sfMixHalfInt].xml',\n",
       " 'm681p04r30#9[sfMixHalfInt].xml',\n",
       " 'm681p04r31#7[sfMixHalfInt].xml',\n",
       " 'm681p2r11#10[sfMixHalfInt].exxd',\n",
       " 'm681p2r2#8[sfMixHalfInt].exxd',\n",
       " 'm681p2r3#8[sfMixHalfInt].exxd',\n",
       " 'm681p2r4#8[sfMixHalfInt].exxd',\n",
       " 'm681p2r5#8[sfMixHalfInt].exxd',\n",
       " 'm681p2r6#13[sfMixHalfInt].exxd',\n",
       " 'm681p2r7#11[sfMixHalfInt].exxd',\n",
       " 'm681p2r7#7[sfMixHalfInt].exxd',\n",
       " 'm681p2r8#9[sfMixHalfInt].exxd',\n",
       " 'm681p2r9#21[sfMixHalfInt].exxd',\n",
       " 'm681p3r5#7[sfMixHalfInt].exxd',\n",
       " 'm681p4r19#8[sfMixHalfInt].exxd',\n",
       " 'm681p4r20#9[sfMixHalfInt].exxd',\n",
       " 'm681p4r22#8[sfMixHalfInt].exxd',\n",
       " 'm681p4r24#11[sfMixHalfInt].exxd',\n",
       " 'm681p4r25#11[sfMixHalfInt].exxd',\n",
       " 'm681p4r26#7[sfMixHalfInt].exxd',\n",
       " 'm681p4r27#9[sfMixHalfInt].exxd',\n",
       " 'm681p4r28#7[sfMixHalfInt].exxd',\n",
       " 'm681p4r29#8[sfMixHalfInt].exxd',\n",
       " 'm681p4r30#9[sfMixHalfInt].exxd',\n",
       " 'm681p4r31#7[sfMixHalfInt].exxd',\n",
       " 'sfMixAlt.exxp',\n",
       " 'sfMixAlt.exxt',\n",
       " 'sfMixFlexTf.exxp',\n",
       " 'sfMixHalfInt.exxp',\n",
       " 'sfMixInt.exxp',\n",
       " 'sfMixInt.exxt',\n",
       " 'sfMixLGNused.exxp',\n",
       " 'sorted']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming files\n",
    "The cell below here is used to rename files so that the unit number [or penetration number] is zero-padded (e.g. '01' instead of '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substr: 2#8[sfMixHalfInt].xm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '2#8[sfMixHalfInt].xm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-56e5a6c203ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msubstr_to_replace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_ind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrEnd_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'substr: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubstr_to_replace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mnew_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr_ind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%02d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstr_to_replace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrEnd_ind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m## else, if updating penetration number (p##)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '2#8[sfMixHalfInt].xm'"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "#     if i.find('#') >= 0:\n",
    "#         os.rename(loc_matData + i, loc_matData + i.replace('#', ''))\n",
    "#         print('IGNORE: renaming %s to %s' % (loc_matData + i, loc_matData + i.replace('#', '')))\n",
    "    if i.find('m681') >=0 and i.find('.xml') >= 0: # .mat; or change to .xml/.exxd if changing names in /recordings\n",
    "\n",
    "        ## if updating unit number ([r/l]##)\n",
    "        r_ind = i.find('r'); # if updating r (unit number)\n",
    "        if r_ind < 0:\n",
    "            r_ind = i.find('l')\n",
    "        pEnd_ind = i.find('#') # if changing in /recordings/;\n",
    "#         rEnd_ind = i.find('_') # if changing in /structures/\n",
    "        substr_to_replace = i[r_ind+1:rEnd_ind]\n",
    "        print('substr: %s' % substr_to_replace)\n",
    "        new_str = i[0:r_ind+1] + '%02d' % int(substr_to_replace) + i[rEnd_ind:]\n",
    "\n",
    "        ## else, if updating penetration number (p##)\n",
    "#         p_ind = i.find('p'); # if updating p (penetration number)\n",
    "#         pEnd_ind = i.find('r') # if changing in /recordings/; will be \"r\" or \"l\"\n",
    "#         substr_to_replace = i[p_ind+1:pEnd_ind]\n",
    "#         print('substr: %s' % substr_to_replace)\n",
    "#         new_str = i[0:p_ind+1] + '%02d' % int(substr_to_replace) + i[pEnd_ind:]\n",
    "\n",
    "        ## finally, the part that applies to both!\n",
    "        if new_str == i:\n",
    "            continue;\n",
    "#         os.rename(loc_matData + i, loc_matData + new_str)\n",
    "        print('renaming %s to %s' % (loc_matData + i, loc_matData + new_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now re-gather the files\n",
    "\n",
    "**If loc_matData != loc_pyData**, *then run this first with loc_matData to convert the .mat files, then a second time to gather all of the .npy files for the datalist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(loc_pyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataList.npy',\n",
       " 'dataList_glx.npy',\n",
       " 'dataList_glx_170.npy',\n",
       " 'dataList_glx_full.npy',\n",
       " 'dataList_glx_mr.npy',\n",
       " 'deprecated_cells',\n",
       " 'descrFits_190503_poiss_flex.npy',\n",
       " 'descrFits_190503_poiss_sach.npy',\n",
       " 'descrFits_190503_sach_flex.npy',\n",
       " 'descrFits_190503_sach_sach.npy',\n",
       " 'descrFits_190503_sqrt_flex.npy',\n",
       " 'descrFits_190503_sqrt_sach.npy',\n",
       " 'descrFits_190916_poiss_flex.npy',\n",
       " 'descrFits_190916_sqrt_flex.npy',\n",
       " 'descrFits_190926_poiss_flex.npy',\n",
       " 'descrFits_190926_sqrt_flex.npy',\n",
       " 'descrFits_191003_poiss_flex.npy',\n",
       " 'descrFits_191003_sqrt_flex.npy',\n",
       " 'descrFits_og_190916_poiss_flex.npy',\n",
       " 'descrFits_og_190916_sqrt_flex.npy',\n",
       " 'descrFits_poiss_sach.npy',\n",
       " 'fitList_190131c_flat_chiSq.npy',\n",
       " 'fitList_190131c_wght_chiSq.npy',\n",
       " 'fitList_190202c_flat_chiSq.npy',\n",
       " 'fitList_190202c_wght_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq_details.npy',\n",
       " 'fitList_190206c_wght_chiSq.npy',\n",
       " 'fitList_190206c_wght_chiSq_details.npy',\n",
       " 'fitList_190226c_flat_chiSq.npy',\n",
       " 'fitList_190226c_wght_chiSq.npy',\n",
       " 'fitList_190301c_flat_chiSq.npy',\n",
       " 'fitList_190301c_flat_chiSq_details.npy',\n",
       " 'fitList_190301c_wght_chiSq.npy',\n",
       " 'fitList_190301c_wght_chiSq_details.npy',\n",
       " 'fitList_190315c_flat_chiSq.npy',\n",
       " 'fitList_190315c_wght_chiSq.npy',\n",
       " 'fitList_190321c_flat_chiSq.npy',\n",
       " 'fitList_190321c_flat_chiSq_details.npy',\n",
       " 'fitList_190321c_wght_chiSq.npy',\n",
       " 'fitList_190321c_wght_chiSq_details.npy',\n",
       " 'fitList_190409cA_flat_chiSq.npy',\n",
       " 'fitList_190409cA_flat_chiSq_details.npy',\n",
       " 'fitList_190409cA_wght_chiSq.npy',\n",
       " 'fitList_190409cA_wght_chiSq_details.npy',\n",
       " 'fitList_190409cB_flat_chiSq.npy',\n",
       " 'fitList_190409cB_flat_chiSq_details.npy',\n",
       " 'fitList_190409cB_wght_chiSq.npy',\n",
       " 'fitList_190409cB_wght_chiSq_details.npy',\n",
       " 'fitList_190426cA_glx_170_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_170_wght_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_wght_chiSq.npy',\n",
       " 'fitList_190428cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190428cA_glx_wght_chiSq.npy',\n",
       " 'fitList_190430cA_glxFull_flat_chiSq.npy',\n",
       " 'fitList_190430cA_glxFull_wght_chiSq.npy',\n",
       " 'fitList_190430cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190430cA_glx_wght_chiSq.npy',\n",
       " 'fitList_190501cA_glx_full_flat_chiSq.npy',\n",
       " 'fitList_190501cA_glx_full_wght_chiSq.npy',\n",
       " 'fitList_190502aA_flat_chiSq.npy',\n",
       " 'fitList_190502aA_wght_chiSq.npy',\n",
       " 'fitList_190502cA_flat_chiSq.npy',\n",
       " 'fitList_190502cA_flat_chiSq_details.npy',\n",
       " 'fitList_190502cA_flex_chiSq.npy',\n",
       " 'fitList_190502cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190502cA_glx_flat_chiSq_details.npy',\n",
       " 'fitList_190502cA_glx_wght_chiSq.npy',\n",
       " 'fitList_190502cA_glx_wght_chiSq_details.npy',\n",
       " 'fitList_190502cA_wght_chiSq.npy',\n",
       " 'fitList_190502cA_wght_chiSq_details.npy',\n",
       " 'fitList_190502cB_flat_chiSq.npy',\n",
       " 'fitList_190502cB_wght_chiSq.npy',\n",
       " 'fitList_190513cA_flat_chiSq.npy',\n",
       " 'fitList_190513cA_wght_chiSq.npy',\n",
       " 'fitList_190515cA_flat_chiSq.npy',\n",
       " 'fitList_190515cA_wght_chiSq.npy',\n",
       " 'fitList_190516cA_flat_chiSq.npy',\n",
       " 'fitList_190516cA_wght_chiSq.npy',\n",
       " 'holdout_fitList_190510cA_flat_chiSq.npy',\n",
       " 'holdout_fitList_190510cA_wght_chiSq.npy',\n",
       " 'holdout_fitList_190510cB_flat_chiSq.npy',\n",
       " 'holdout_fitList_190510cB_wght_chiSq.npy',\n",
       " 'holdout_fitList_190511cA_flat_chiSq.npy',\n",
       " 'holdout_fitList_190511cA_wght_chiSq.npy',\n",
       " 'holdout_fitList_190511cB_flat_chiSq.npy',\n",
       " 'holdout_fitList_190511cB_wght_chiSq.npy',\n",
       " 'holdout_fitList_190513cA_flat_chiSq.npy',\n",
       " 'holdout_fitList_190513cA_wght_chiSq.npy',\n",
       " 'm676l01_glx182_sfm.mat',\n",
       " 'm676l01_glx182_sfm.npy',\n",
       " 'm676p3l06_154_sfm.npy',\n",
       " 'm676p3l06_glx_170_sfm.mat',\n",
       " 'm676p3l06_glx_170_sfm.npy',\n",
       " 'm676p3l07_154_sfm.npy',\n",
       " 'm676p3l07_glx_sfm.mat',\n",
       " 'm676p3l07_glx_sfm.npy',\n",
       " 'm676p3l13_c40_sfm.mat',\n",
       " 'm676p3l13_c40_sfm.npy',\n",
       " 'm676p3l13_c46_sfm.mat',\n",
       " 'm676p3l13_c46_sfm.npy',\n",
       " 'm676p3l13_sfm.mat',\n",
       " 'm676p3l13_sfm.npy',\n",
       " 'm676p3l15_glx63_sfm.mat',\n",
       " 'm676p3l15_glx63_sfm.npy',\n",
       " 'm676p3l15_glx_sfm.mat',\n",
       " 'm676p3l15_glx_sfm.npy',\n",
       " 'm678p5l06_glx170_sfm.mat',\n",
       " 'm678p5l06_glx170_sfm.npy',\n",
       " 'm678p5l06_glx174_sfm.mat',\n",
       " 'm678p5l06_glx174_sfm.npy',\n",
       " 'm678p5l06_glx195_sfm.mat',\n",
       " 'm678p5l06_glx195_sfm.npy',\n",
       " 'm678p5l07_glx_sfm.mat',\n",
       " 'm678p5l07_glx_sfm.npy',\n",
       " 'm678p6l11_c4_sfm.mat',\n",
       " 'm678p6l11_c4_sfm.npy',\n",
       " 'm678p6l11_c96_sfm.mat',\n",
       " 'm678p6l11_c96_sfm.npy',\n",
       " 'm678p6l11_glx_sfm.mat',\n",
       " 'm678p6l11_glx_sfm.npy',\n",
       " 'm678p6l12_c11_sfm.mat',\n",
       " 'm678p6l12_c11_sfm.npy',\n",
       " 'm678p6l12_c911_sfm.mat',\n",
       " 'm678p6l12_c911_sfm.npy',\n",
       " 'm678p6l12_c9_sfm.mat',\n",
       " 'm678p6l12_c9_sfm.npy',\n",
       " 'm678p6l12_glx_sfm.mat',\n",
       " 'm678p6l12_glx_sfm.npy',\n",
       " 'm678p6l15_glx41_sfm.mat',\n",
       " 'm678p6l15_glx41_sfm.npy',\n",
       " 'm678p6l16_glx_sfm.mat',\n",
       " 'm678p6l16_glx_sfm.npy',\n",
       " 'm678p6l18_c17_sfm.mat',\n",
       " 'm678p6l18_c17_sfm.npy',\n",
       " 'm678p6l18_c45_sfm.mat',\n",
       " 'm678p6l18_c45_sfm.npy',\n",
       " 'm678p6l18_c59_sfm.mat',\n",
       " 'm678p6l18_c59_sfm.npy',\n",
       " 'm678p6l18_c69_sfm.mat',\n",
       " 'm678p6l18_c69_sfm.npy',\n",
       " 'm678p6l18_glx55_sfm.mat',\n",
       " 'm678p6l18_glx55_sfm.npy',\n",
       " 'm678p7r03_c27_sfm.mat',\n",
       " 'm678p7r03_c27_sfm.npy',\n",
       " 'm678p7r03_c32_sfm.mat',\n",
       " 'm678p7r03_c32_sfm.npy',\n",
       " 'm678p7r03_c36_sfm.mat',\n",
       " 'm678p7r03_c36_sfm.npy',\n",
       " 'm678p7r03_c39_sfm.mat',\n",
       " 'm678p7r03_c39_sfm.npy',\n",
       " 'm678p7r03_c69_sfm.mat',\n",
       " 'm678p7r03_c69_sfm.npy',\n",
       " 'm678p7r03_c72_sfm.mat',\n",
       " 'm678p7r03_c72_sfm.npy',\n",
       " 'm678p7r03_glx_sfm.mat',\n",
       " 'm678p7r03_glx_sfm.npy',\n",
       " 'm681p02r02#8_sfm.mat',\n",
       " 'm681p02r02#8_sfm.npy',\n",
       " 'm681p02r03#8_sfm.mat',\n",
       " 'm681p02r03#8_sfm.npy',\n",
       " 'm681p02r04#8_sfm.mat',\n",
       " 'm681p02r04#8_sfm.npy',\n",
       " 'm681p02r05#8_sfm.mat',\n",
       " 'm681p02r05#8_sfm.npy',\n",
       " 'm681p02r06#13_sfm.mat',\n",
       " 'm681p02r06#13_sfm.npy',\n",
       " 'm681p02r07#11_sfm.mat',\n",
       " 'm681p02r07#11_sfm.npy',\n",
       " 'm681p02r07#7_sfm.mat',\n",
       " 'm681p02r07#7_sfm.npy',\n",
       " 'm681p02r08#9_sfm.mat',\n",
       " 'm681p02r08#9_sfm.npy',\n",
       " 'm681p02r09#21_sfm.mat',\n",
       " 'm681p02r09#21_sfm.npy',\n",
       " 'm681p02r11#10_sfm.mat',\n",
       " 'm681p02r11#10_sfm.npy',\n",
       " 'm681p03r05#7_sfm.mat',\n",
       " 'm681p03r05#7_sfm.npy',\n",
       " 'm681p04r19#8_sfm.mat',\n",
       " 'm681p04r19#8_sfm.npy',\n",
       " 'm681p04r20#9_sfm.mat',\n",
       " 'm681p04r20#9_sfm.npy',\n",
       " 'm681p04r22#8_sfm.mat',\n",
       " 'm681p04r22#8_sfm.npy',\n",
       " 'm681p04r24#11_sfm.mat',\n",
       " 'm681p04r24#11_sfm.npy',\n",
       " 'm681p04r25#11_sfm.mat',\n",
       " 'm681p04r25#11_sfm.npy',\n",
       " 'm681p04r26#7_sfm.mat',\n",
       " 'm681p04r26#7_sfm.npy',\n",
       " 'm681p04r27#9_sfm.mat',\n",
       " 'm681p04r27#9_sfm.npy',\n",
       " 'm681p04r29#8_sfm.mat',\n",
       " 'm681p04r29#8_sfm.npy',\n",
       " 'm681p04r30#9_sfm.mat',\n",
       " 'm681p04r30#9_sfm.npy',\n",
       " 'm681p04r31#7_sfm.mat',\n",
       " 'm681p04r31#7_sfm.npy',\n",
       " 'mr10_m676p3l15_glx_sfm.npy',\n",
       " 'mr11_m676p3l15_glx_sfm.npy',\n",
       " 'mr12_m676p3l15_glx_sfm.npy',\n",
       " 'mr13_m676p3l15_glx_sfm.npy',\n",
       " 'mr14_m676p3l15_glx_sfm.npy',\n",
       " 'mr15_m676p3l15_glx_sfm.npy',\n",
       " 'mr1_m676p3l15_glx_sfm.npy',\n",
       " 'mr2_m676p3l15_glx_sfm.npy',\n",
       " 'mr3_m676p3l15_glx_sfm.npy',\n",
       " 'mr4_m676p3l15_glx_sfm.npy',\n",
       " 'mr5_m676p3l15_glx_sfm.npy',\n",
       " 'mr6_m676p3l15_glx_sfm.npy',\n",
       " 'mr7_m676p3l15_glx_sfm.npy',\n",
       " 'mr8_m676p3l15_glx_sfm.npy',\n",
       " 'mr9_m676p3l15_glx_sfm.npy',\n",
       " 'mr_fitList_190502cA_flat_chiSq.npy',\n",
       " 'mr_fitList_190502cA_wght_chiSq.npy',\n",
       " 'mr_flat_descrFits_190503_poiss_flex.npy',\n",
       " 'mr_flat_rvcFits_f0.npy',\n",
       " 'mr_wght_descrFits_190503_poiss_flex.npy',\n",
       " 'mr_wght_rvcFits_f0.npy',\n",
       " 'phaseAdvanceFitsTest_neg.npy',\n",
       " 'phaseAdvanceFitsTest_pos.npy',\n",
       " 'phaseAdvanceFits_190828_orig_pos.npy',\n",
       " 'phaseAdvanceFits_190828_pos.npy',\n",
       " 'phaseAdvanceFits_190916_pos.npy',\n",
       " 'phaseAdvanceFits_191003_pos.npy',\n",
       " 'rvcFitsTest_neg.npy',\n",
       " 'rvcFitsTest_pos.npy',\n",
       " 'rvcFits_190828_f1_neg.npy',\n",
       " 'rvcFits_190828_f1_orig_pos.npy',\n",
       " 'rvcFits_190828_f1_pos.npy',\n",
       " 'rvcFits_190916_f0.npy',\n",
       " 'rvcFits_190916_f1.npy',\n",
       " 'rvcFits_190916_f1_og_pos.npy',\n",
       " 'rvcFits_190916_f1_pos.npy',\n",
       " 'rvcFits_190926_f0.npy',\n",
       " 'rvcFits_191003_NR_f1_pos.npy',\n",
       " 'rvcFits_191003_f0.npy',\n",
       " 'rvcFits_191003_f1_pos.npy',\n",
       " 'rvcFits_f0.npy',\n",
       " 'rvcFits_pos.npy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert individual files\n",
    "unitName = [];\n",
    "expType  = [];\n",
    "unitArea = [];\n",
    "for i in files:\n",
    "    # if file has 'sfm' in it and starts with m then \n",
    "    if i.find('sfm') >= 0 and i.startswith('m6'):\n",
    "        \n",
    "        # don't convert if it already exists\n",
    "        if os.path.exists(loc_pyData + i.replace('.mat', '.npy')):\n",
    "            if i.endswith('.npy') and i.find('fullWave') == -1: # only add once (not also with .mat)\n",
    "                # unit name will be everything up to \"_sfm\"\n",
    "                unitName.append(i[0:i.find('_sfm')]) # go up to the '_sfm' character\n",
    "                # but the core name is just up to the first \"_\" (i.e. m#X(l/r)#Y)\n",
    "                _, expName = hf.get_exp_ind(loc_pyData, i[0:i.find('_')])\n",
    "                if expName is None:\n",
    "                    pdb.set_trace();\n",
    "                expType.append(expName);\n",
    "                unitArea.append(recArea)\n",
    "            continue;\n",
    "                \n",
    "        print(\"loading: \" + i)\n",
    "        matData = makeStimulus.loadmat(loc_matData + i);\n",
    "        S = matData.get('S'); # the actual data structure\n",
    "        _, expName = hf.get_exp_ind(loc_pyData, i[0:i.find('_')])\n",
    "        \n",
    "        print(\"now saving...\")\n",
    "        saveName = loc_pyData + i.replace('.mat', '.npy');\n",
    "        np.save(saveName, S)\n",
    "        \n",
    "        unitName.append(i[0:i.find('_')]) # go up to the '_' character\n",
    "        expType.append(expName);\n",
    "        unitArea.append(recArea);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676l01_glx182',\n",
       " 'm676p3l06_154',\n",
       " 'm676p3l06_glx_170',\n",
       " 'm676p3l07_154',\n",
       " 'm676p3l07_glx',\n",
       " 'm676p3l13_c40',\n",
       " 'm676p3l13_c46',\n",
       " 'm676p3l13',\n",
       " 'm676p3l15_glx63',\n",
       " 'm676p3l15_glx',\n",
       " 'm678p5l06_glx170',\n",
       " 'm678p5l06_glx174',\n",
       " 'm678p5l06_glx195',\n",
       " 'm678p5l07_glx',\n",
       " 'm678p6l11_c4',\n",
       " 'm678p6l11_c96',\n",
       " 'm678p6l11_glx',\n",
       " 'm678p6l12_c11',\n",
       " 'm678p6l12_c911',\n",
       " 'm678p6l12_c9',\n",
       " 'm678p6l12_glx',\n",
       " 'm678p6l15_glx41',\n",
       " 'm678p6l16_glx',\n",
       " 'm678p6l18_c17',\n",
       " 'm678p6l18_c45',\n",
       " 'm678p6l18_c59',\n",
       " 'm678p6l18_c69',\n",
       " 'm678p6l18_glx55',\n",
       " 'm678p7r03_c27',\n",
       " 'm678p7r03_c32',\n",
       " 'm678p7r03_c36',\n",
       " 'm678p7r03_c39',\n",
       " 'm678p7r03_c69',\n",
       " 'm678p7r03_c72',\n",
       " 'm678p7r03_glx',\n",
       " 'm681p02r02#8',\n",
       " 'm681p02r03#8',\n",
       " 'm681p02r04#8',\n",
       " 'm681p02r05#8',\n",
       " 'm681p02r06#13',\n",
       " 'm681p02r07#11',\n",
       " 'm681p02r07#7',\n",
       " 'm681p02r08#9',\n",
       " 'm681p02r09#21',\n",
       " 'm681p02r11#10',\n",
       " 'm681p03r05#7',\n",
       " 'm681p04r19#8',\n",
       " 'm681p04r20#9',\n",
       " 'm681p04r22#8',\n",
       " 'm681p04r24#11',\n",
       " 'm681p04r25#11',\n",
       " 'm681p04r26#7',\n",
       " 'm681p04r27#9',\n",
       " 'm681p04r29#8',\n",
       " 'm681p04r30#9',\n",
       " 'm681p04r31#7']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/update data list\n",
    "\n",
    "Run the above if you haven't yet and want to update the datalist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_name = 'dataList_safe.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = hf.np_smart_load(loc_pyData + dl_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-96fa94538f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unitName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "dataList['unitName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(loc_pyData + dl_name):\n",
    "    dataList = hf.np_smart_load(loc_pyData + dl_name);\n",
    "    dataList['unitName'] = unitName;\n",
    "    dataList['unitArea'] = unitArea;\n",
    "    dataList['expType'] = expType;\n",
    "    np.save(loc_pyData + dl_name, dataList);\n",
    "else: # unitType, isolation, comment must be filled in by hand at later time\n",
    "    dataList = dict();\n",
    "    dataList['unitName'] = unitName;\n",
    "    dataList['unitArea'] = unitArea;\n",
    "    dataList['expType'] = expType;\n",
    "    dataList['expType'] = expType;\n",
    "    dataList['isolation'] = [];\n",
    "    dataList['comment'] = [];\n",
    "    np.save(loc_pyData + dl_name, dataList);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the saved/updated data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = np.load(loc_pyData + dl_name).item();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676l01_glx182',\n",
       " 'm676p3l06_154',\n",
       " 'm676p3l06_glx_170',\n",
       " 'm676p3l07_154',\n",
       " 'm676p3l07_glx',\n",
       " 'm676p3l13_c40',\n",
       " 'm676p3l13_c46',\n",
       " 'm676p3l13',\n",
       " 'm676p3l15_glx63',\n",
       " 'm676p3l15_glx',\n",
       " 'm678p5l06_glx170',\n",
       " 'm678p5l06_glx174',\n",
       " 'm678p5l06_glx195',\n",
       " 'm678p5l07_glx',\n",
       " 'm678p6l11_c4',\n",
       " 'm678p6l11_c96',\n",
       " 'm678p6l11_glx',\n",
       " 'm678p6l12_c11',\n",
       " 'm678p6l12_c911',\n",
       " 'm678p6l12_c9',\n",
       " 'm678p6l12_glx',\n",
       " 'm678p6l15_glx41',\n",
       " 'm678p6l16_glx',\n",
       " 'm678p6l18_c17',\n",
       " 'm678p6l18_c45',\n",
       " 'm678p6l18_c59',\n",
       " 'm678p6l18_c69',\n",
       " 'm678p6l18_glx55',\n",
       " 'm678p7r03_c27',\n",
       " 'm678p7r03_c32',\n",
       " 'm678p7r03_c36',\n",
       " 'm678p7r03_c39',\n",
       " 'm678p7r03_c69',\n",
       " 'm678p7r03_c72',\n",
       " 'm678p7r03_glx',\n",
       " 'm681p02r02#8',\n",
       " 'm681p02r03#8',\n",
       " 'm681p02r04#8',\n",
       " 'm681p02r05#8',\n",
       " 'm681p02r06#13',\n",
       " 'm681p02r07#11',\n",
       " 'm681p02r07#7',\n",
       " 'm681p02r08#9',\n",
       " 'm681p02r09#21',\n",
       " 'm681p02r11#10',\n",
       " 'm681p03r05#7',\n",
       " 'm681p04r19#8',\n",
       " 'm681p04r20#9',\n",
       " 'm681p04r22#8',\n",
       " 'm681p04r24#11',\n",
       " 'm681p04r25#11',\n",
       " 'm681p04r26#7',\n",
       " 'm681p04r27#9',\n",
       " 'm681p04r29#8',\n",
       " 'm681p04r30#9',\n",
       " 'm681p04r31#7']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList['unitName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other changes\n",
    "Likely not needed, this section was from converting the previous data set where normalization responses where already computed in Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change some things around...\n",
    "for i in dataList['unitName']:\n",
    "\n",
    "    print(\"changing: \" + i)\n",
    "    S = np.load(loc_pyData + i + '_sfm.npy').item(); # the actual data structure\n",
    "    \n",
    "    if S.get('sfm').get('mod'):\n",
    "        if S.get('sfm').get('mod').get('normalization') and S.get('sfm').get('mod').get('normalization_py'):\n",
    "            \n",
    "            S['sfm']['mod']['norm_old'] = S['sfm']['mod']['normalization'];\n",
    "            S['sfm']['mod']['normalization'] = S['sfm']['mod']['normalization_py'];\n",
    "            S['sfm']['mod'].pop('normalization_py');\n",
    "            \n",
    "            print(\"now saving...\")\n",
    "            saveName = loc_pyData + i + '_sfm.npy';\n",
    "            np.save(saveName, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General 'update python structs' here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this section to update something about each cell in the dataList (change appropriate field(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of analysis in sandbox_careful.ipynb, I've determined that the F1 calculation is in correct, as provided in the matlab files which we use to load the expo XML files. Thus, the 'f1' field associated with each cell has a value which is usually half the true F1 power. Why? Given the nature of the spike train as a real signal, the power at non-DC, positive-frequencies should be doubled from what is calculated in the FFT (see sandbox_careful.ipynb and helper_fcns.py/spike_fft for more details).\n",
    "\n",
    "Below, I'll use this template to load each cell, move the 'f1' field to 'expo_f1', and create a new 'f1' field with the correct calculation.\n",
    "\n",
    "**NOTE:** Now that this move has been completed, do not run the line below \"now let's move the 'f1' field\", since you will then overwrite the original expo F1 calculation ('f1_expo') with our own calculation (now stored in 'f1')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expDirs = ['V1_orig/', 'altExp/', 'V1/']\n",
    "expNames = ['dataList.npy', 'dataList.npy', 'dataList_glx.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: V1_orig/\n",
      "dir: altExp/\n",
      "dir: V1/\n"
     ]
    }
   ],
   "source": [
    "for expDir, dL_nm in zip(expDirs, expNames):\n",
    "\n",
    "    data_loc = base_loc + expDir + 'structures/';\n",
    "    dataList = hf.np_smart_load(data_loc + dL_nm);\n",
    "\n",
    "    print('dir: %s' % expDir)\n",
    "    \n",
    "    # Now, go through for each cell in the dataList                                                                                                                                                                                                                           \n",
    "    nCells = len(dataList['unitName']);\n",
    "    for cell_ind in range(nCells):\n",
    "\n",
    "        # get experiment name, load cell                                                                                                                                                                                                                                        \n",
    "        expName = dataList['unitName'][cell_ind];\n",
    "        expInd = hf.get_exp_ind(data_loc, expName)[0];\n",
    "        cell = hf.np_smart_load(data_loc + expName + '_sfm.npy');\n",
    "        tr_inf = cell['sfm']['exp']['trial']\n",
    "        \n",
    "        # now, let's \"move\" the 'f1' field\n",
    "#         cell['sfm']['exp']['trial']['f1_expo'] = cell['sfm']['exp']['trial']['f1'];\n",
    "        # the real stuff: get the correct f1 calculation\n",
    "        nTrials = len(tr_inf['num']);\n",
    "        stimDur = hf.get_exp_params(expInd, forceDir=expDir).stimDur;\n",
    "        spike_times = [tr_inf['spikeTimes'][x] for x in range(nTrials)]; \n",
    "        psth, bins = hf.make_psth(spike_times, stimDur=stimDur);\n",
    "        n_trs = len(tr_inf['num']);\n",
    "        try: # V1_orig does not have num_comps, but we cannot properly do f1 by component for mixtures with V1_orig (nor altExp)\n",
    "            n_comps = tr_inf['num_comps']\n",
    "            all_tf = [[tr_inf['tf'][c_i][i] for c_i in range(x)] for i, x in enumerate(n_comps)];\n",
    "        except: # so in that case, just get the first grating from each trial\n",
    "            all_tf = tr_inf['tf'][0]; # just take first grating???\n",
    "        power, rel_power, full_ft = hf.spike_fft(psth, tfs=all_tf, stimDur=stimDur);\n",
    "    \n",
    "        cell['sfm']['exp']['trial']['f1'] = rel_power;\n",
    "        \n",
    "        # then save the update!\n",
    "        np.save(data_loc + expName + '_sfm.npy', cell);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed (19.05.12) some cells were not fitting/plotting, due to error in summing total_con it turns out that was caused by *con.shape = (nComps, nTrials) rather than (nComps, ); here, we fix that issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL = np.load(loc_pyData + 'dataList.npy').item();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dL['unitName']:\n",
    "    S = hf.np_smart_load(loc_pyData + i + '_sfm.npy');\n",
    "        \n",
    "    trial = S['sfm']['exp']['trial'];\n",
    "    cons = trial['con'];\n",
    "\n",
    "    if len(cons.shape) == 2:\n",
    "        print('ha! issue with %s' % i);\n",
    "        nComps = cons.shape[0];\n",
    "        newCons = np.zeros((nComps, ), dtype='O')\n",
    "        # for each component, pack as array, which is the default/working method\n",
    "        for ci in range(nComps):\n",
    "            newCons[ci] = np.array(cons[ci, :])\n",
    "        \n",
    "        S['sfm']['exp']['trial']['con'] = newCons;\n",
    "        np.save(loc_pyData + i + '_sfm.npy', S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
