{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting matlab data into python\n",
    "\n",
    "Last update (ymd): 19.09.11  \n",
    "Last access (ymd): 19.09.16   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this Jupyter notebook to convert Expo data from .mat to .npy files, and to make adjustments to existing .npy files (e.g. renaming fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, os\n",
    "import sys\n",
    "sys.path.insert(0, 'functions/'); # add this path for makeStimulus\n",
    "import makeStimulus\n",
    "import helper_fcns as hf\n",
    "import autoreload\n",
    "\n",
    "import pdb\n",
    "\n",
    "# constants - directories\n",
    "base_loc = '/arc/2.2/p1/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/';\n",
    "# base_loc = '/users/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/';\n",
    "\n",
    "loc_matData = 'V1/structuresTest/'; # where are the .mat files?\n",
    "loc_pyData = 'V1/structures/'; # where do you want the .npy files?\n",
    "\n",
    "recArea = 'V1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The original conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the .mat files to convert; then, convert unless already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(loc_matData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676p3l6_154_sfm.mat', 'm676p3l7_154_sfm.mat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming files\n",
    "The cell below here is used to rename files so that the unit number is zero-padded (e.g. '01' instead of '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renaming V1/structuresTest/m676p3l6_154_sfm.mat to V1/structuresTest/m676p3l06_154_sfm.mat\n",
      "renaming V1/structuresTest/m676p3l7_154_sfm.mat to V1/structuresTest/m676p3l07_154_sfm.mat\n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "#     if i.find('#') >= 0:\n",
    "#         os.rename(loc_matData + i, loc_matData + i.replace('#', ''))\n",
    "#         print('IGNORE: renaming %s to %s' % (loc_matData + i, loc_matData + i.replace('#', '')))\n",
    "    if i.find('m676') >=0 and i.find('.mat') >= 0: # or change to .xml/.exxd if changing names in /recordings\n",
    "        r_ind = i.find('r');\n",
    "        if r_ind < 0:\n",
    "            r_ind = i.find('l')\n",
    "            \n",
    "#         rEnd_ind = i.find('#') # if changing in /recordings/\n",
    "        rEnd_ind = i.find('_') # if changing in /structures/\n",
    "        substr_to_replace = i[r_ind+1:rEnd_ind]\n",
    "#         print('substr: %s' % substr_to_replace)\n",
    "        new_str = i[0:r_ind+1] + '%02d' % int(substr_to_replace) + i[rEnd_ind:]\n",
    "        if new_str == i:\n",
    "            continue;\n",
    "        os.rename(loc_matData + i, loc_matData + new_str)\n",
    "        print('renaming %s to %s' % (loc_matData + i, loc_matData + new_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now re-gather the files\n",
    "\n",
    "**If loc_matData != loc_pyData**, *then run this first with loc_matData to convert the .mat files, then a second time to gather all of the .npy files for the datalist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(loc_pyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataList.npy',\n",
       " 'dataList_glx.npy',\n",
       " 'dataList_glx_170.npy',\n",
       " 'dataList_glx_full.npy',\n",
       " 'dataList_glx_mr.npy',\n",
       " 'deprecated_cells',\n",
       " 'descrFits_190503_poiss_flex.npy',\n",
       " 'descrFits_190503_poiss_sach.npy',\n",
       " 'descrFits_190503_sach_flex.npy',\n",
       " 'descrFits_190503_sach_sach.npy',\n",
       " 'descrFits_190503_sqrt_flex.npy',\n",
       " 'descrFits_190503_sqrt_sach.npy',\n",
       " 'descrFits_poiss_sach.npy',\n",
       " 'fitList_190131c_flat_chiSq.npy',\n",
       " 'fitList_190131c_wght_chiSq.npy',\n",
       " 'fitList_190202c_flat_chiSq.npy',\n",
       " 'fitList_190202c_wght_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq_details.npy',\n",
       " 'fitList_190206c_wght_chiSq.npy',\n",
       " 'fitList_190206c_wght_chiSq_details.npy',\n",
       " 'fitList_190226c_flat_chiSq.npy',\n",
       " 'fitList_190226c_wght_chiSq.npy',\n",
       " 'fitList_190301c_flat_chiSq.npy',\n",
       " 'fitList_190301c_flat_chiSq_details.npy',\n",
       " 'fitList_190301c_wght_chiSq.npy',\n",
       " 'fitList_190301c_wght_chiSq_details.npy',\n",
       " 'fitList_190315c_flat_chiSq.npy',\n",
       " 'fitList_190315c_wght_chiSq.npy',\n",
       " 'fitList_190321c_flat_chiSq.npy',\n",
       " 'fitList_190321c_flat_chiSq_details.npy',\n",
       " 'fitList_190321c_wght_chiSq.npy',\n",
       " 'fitList_190321c_wght_chiSq_details.npy',\n",
       " 'fitList_190409cA_flat_chiSq.npy',\n",
       " 'fitList_190409cA_flat_chiSq_details.npy',\n",
       " 'fitList_190409cA_wght_chiSq.npy',\n",
       " 'fitList_190409cA_wght_chiSq_details.npy',\n",
       " 'fitList_190409cB_flat_chiSq.npy',\n",
       " 'fitList_190409cB_flat_chiSq_details.npy',\n",
       " 'fitList_190409cB_wght_chiSq.npy',\n",
       " 'fitList_190409cB_wght_chiSq_details.npy',\n",
       " 'fitList_190426cA_glx_170_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_170_wght_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_wght_chiSq.npy',\n",
       " 'fitList_190428cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190428cA_glx_wght_chiSq.npy',\n",
       " 'fitList_190430cA_glxFull_flat_chiSq.npy',\n",
       " 'fitList_190430cA_glxFull_wght_chiSq.npy',\n",
       " 'fitList_190430cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190430cA_glx_wght_chiSq.npy',\n",
       " 'fitList_190501cA_glx_full_flat_chiSq.npy',\n",
       " 'fitList_190501cA_glx_full_wght_chiSq.npy',\n",
       " 'fitList_190502aA_flat_chiSq.npy',\n",
       " 'fitList_190502aA_wght_chiSq.npy',\n",
       " 'fitList_190502cA_flat_chiSq.npy',\n",
       " 'fitList_190502cA_flat_chiSq_details.npy',\n",
       " 'fitList_190502cA_flex_chiSq.npy',\n",
       " 'fitList_190502cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190502cA_glx_flat_chiSq_details.npy',\n",
       " 'fitList_190502cA_glx_wght_chiSq.npy',\n",
       " 'fitList_190502cA_glx_wght_chiSq_details.npy',\n",
       " 'fitList_190502cA_wght_chiSq.npy',\n",
       " 'fitList_190502cA_wght_chiSq_details.npy',\n",
       " 'fitList_190502cB_flat_chiSq.npy',\n",
       " 'fitList_190502cB_wght_chiSq.npy',\n",
       " 'fitList_190513cA_flat_chiSq.npy',\n",
       " 'fitList_190513cA_wght_chiSq.npy',\n",
       " 'fitList_190515cA_flat_chiSq.npy',\n",
       " 'fitList_190515cA_wght_chiSq.npy',\n",
       " 'fitList_190516cA_flat_chiSq.npy',\n",
       " 'fitList_190516cA_wght_chiSq.npy',\n",
       " 'holdout_fitList_190510cA_flat_chiSq.npy',\n",
       " 'holdout_fitList_190510cA_wght_chiSq.npy',\n",
       " 'holdout_fitList_190510cB_flat_chiSq.npy',\n",
       " 'holdout_fitList_190510cB_wght_chiSq.npy',\n",
       " 'holdout_fitList_190511cA_flat_chiSq.npy',\n",
       " 'holdout_fitList_190511cA_wght_chiSq.npy',\n",
       " 'holdout_fitList_190511cB_flat_chiSq.npy',\n",
       " 'holdout_fitList_190511cB_wght_chiSq.npy',\n",
       " 'holdout_fitList_190513cA_flat_chiSq.npy',\n",
       " 'holdout_fitList_190513cA_wght_chiSq.npy',\n",
       " 'm676l01_glx182_sfm.mat',\n",
       " 'm676l01_glx182_sfm.npy',\n",
       " 'm676p3l06_154_sfm.npy',\n",
       " 'm676p3l06_glx_170_sfm.mat',\n",
       " 'm676p3l06_glx_170_sfm.npy',\n",
       " 'm676p3l07_154_sfm.npy',\n",
       " 'm676p3l07_glx_sfm.mat',\n",
       " 'm676p3l07_glx_sfm.npy',\n",
       " 'm676p3l13_sfm.mat',\n",
       " 'm676p3l13_sfm.npy',\n",
       " 'm676p3l15_glx_sfm.mat',\n",
       " 'm676p3l15_glx_sfm.npy',\n",
       " 'm678p5l06_glx170_sfm.mat',\n",
       " 'm678p5l06_glx170_sfm.npy',\n",
       " 'm678p5l06_glx174_sfm.mat',\n",
       " 'm678p5l06_glx174_sfm.npy',\n",
       " 'm678p5l07_glx_sfm.mat',\n",
       " 'm678p5l07_glx_sfm.npy',\n",
       " 'm678p6l11_glx_sfm.mat',\n",
       " 'm678p6l11_glx_sfm.npy',\n",
       " 'm678p6l12_glx_sfm.mat',\n",
       " 'm678p6l12_glx_sfm.npy',\n",
       " 'm678p6l15_glx41_sfm.mat',\n",
       " 'm678p6l15_glx41_sfm.npy',\n",
       " 'm678p6l16_glx_sfm.mat',\n",
       " 'm678p6l16_glx_sfm.npy',\n",
       " 'm678p6l18_glx55_sfm.mat',\n",
       " 'm678p6l18_glx55_sfm.npy',\n",
       " 'm678p7r03_glx_sfm.mat',\n",
       " 'm678p7r03_glx_sfm.npy',\n",
       " 'mr10_m676p3l15_glx_sfm.npy',\n",
       " 'mr11_m676p3l15_glx_sfm.npy',\n",
       " 'mr12_m676p3l15_glx_sfm.npy',\n",
       " 'mr13_m676p3l15_glx_sfm.npy',\n",
       " 'mr14_m676p3l15_glx_sfm.npy',\n",
       " 'mr15_m676p3l15_glx_sfm.npy',\n",
       " 'mr1_m676p3l15_glx_sfm.npy',\n",
       " 'mr2_m676p3l15_glx_sfm.npy',\n",
       " 'mr3_m676p3l15_glx_sfm.npy',\n",
       " 'mr4_m676p3l15_glx_sfm.npy',\n",
       " 'mr5_m676p3l15_glx_sfm.npy',\n",
       " 'mr6_m676p3l15_glx_sfm.npy',\n",
       " 'mr7_m676p3l15_glx_sfm.npy',\n",
       " 'mr8_m676p3l15_glx_sfm.npy',\n",
       " 'mr9_m676p3l15_glx_sfm.npy',\n",
       " 'mr_fitList_190502cA_flat_chiSq.npy',\n",
       " 'mr_fitList_190502cA_wght_chiSq.npy',\n",
       " 'mr_flat_descrFits_190503_poiss_flex.npy',\n",
       " 'mr_flat_rvcFits_f0.npy',\n",
       " 'mr_wght_descrFits_190503_poiss_flex.npy',\n",
       " 'mr_wght_rvcFits_f0.npy',\n",
       " 'phaseAdvanceFitsTest_neg.npy',\n",
       " 'phaseAdvanceFitsTest_pos.npy',\n",
       " 'phaseAdvanceFits_190828_orig_pos.npy',\n",
       " 'phaseAdvanceFits_190828_pos.npy',\n",
       " 'phaseAdvanceFits_190905_pos.npy',\n",
       " 'rvcFitsTest_neg.npy',\n",
       " 'rvcFitsTest_pos.npy',\n",
       " 'rvcFits_190828_f1_neg.npy',\n",
       " 'rvcFits_190828_f1_orig_pos.npy',\n",
       " 'rvcFits_190828_f1_pos.npy',\n",
       " 'rvcFits_190905_pos.npy',\n",
       " 'rvcFits_f0.npy',\n",
       " 'rvcFits_pos.npy']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert individual files\n",
    "unitName = [];\n",
    "expType  = [];\n",
    "unitArea = [];\n",
    "for i in files:\n",
    "    # if file has 'sfm' in it and starts with m then \n",
    "    if i.find('sfm') >= 0 and i.startswith('m6'):\n",
    "        \n",
    "        # don't convert if it already exists\n",
    "        if os.path.exists(loc_pyData + i.replace('.mat', '.npy')):\n",
    "            if i.endswith('.npy') and i.find('fullWave') == -1: # only add once (not also with .mat)\n",
    "                unitName.append(i[0:i.find('_sfm')]) # go up to the '_sfm' character\n",
    "                _, expName = hf.get_exp_ind(loc_pyData, i[0:i.find('_')])\n",
    "                if expName is None:\n",
    "                    pdb.set_trace();\n",
    "                expType.append(expName);\n",
    "                unitArea.append(recArea)\n",
    "            continue;\n",
    "                \n",
    "        print(\"loading: \" + i)\n",
    "        matData = makeStimulus.loadmat(loc_matData + i);\n",
    "        S = matData.get('S'); # the actual data structure\n",
    "        _, expName = hf.get_exp_ind(loc_pyData, i[0:i.find('_')])\n",
    "        \n",
    "        print(\"now saving...\")\n",
    "        saveName = loc_pyData + i.replace('.mat', '.npy');\n",
    "        np.save(saveName, S)\n",
    "        \n",
    "        unitName.append(i[0:i.find('_')]) # go up to the '_' character\n",
    "        expType.append(expName);\n",
    "        unitArea.append(recArea);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676l01_glx182',\n",
       " 'm676p3l06_154',\n",
       " 'm676p3l06_glx_170',\n",
       " 'm676p3l07_154',\n",
       " 'm676p3l07_glx',\n",
       " 'm676p3l13',\n",
       " 'm676p3l15_glx',\n",
       " 'm678p5l06_glx170',\n",
       " 'm678p5l06_glx174',\n",
       " 'm678p5l07_glx',\n",
       " 'm678p6l11_glx',\n",
       " 'm678p6l12_glx',\n",
       " 'm678p6l15_glx41',\n",
       " 'm678p6l16_glx',\n",
       " 'm678p6l18_glx55',\n",
       " 'm678p7r03_glx']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/update data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_name = 'dataList_glx.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = hf.np_smart_load(loc_pyData + dl_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676l01_glx182',\n",
       " 'm676p3l06_glx_170',\n",
       " 'm676p3l07_154',\n",
       " 'm676p3l07_glx',\n",
       " 'm676p3l13',\n",
       " 'm676p3l15_glx',\n",
       " 'm678p5l06_glx170',\n",
       " 'm678p5l06_glx174',\n",
       " 'm678p5l07_glx',\n",
       " 'm678p6l11_glx',\n",
       " 'm678p6l12_glx',\n",
       " 'm678p6l15_glx41',\n",
       " 'm678p6l16_glx',\n",
       " 'm678p6l18_glx55',\n",
       " 'm678p7r03_glx']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList['unitName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(loc_pyData + dl_name):\n",
    "    dataList = hf.np_smart_load(loc_pyData + dl_name);\n",
    "    dataList['unitName'] = unitName;\n",
    "    dataList['unitArea'] = unitArea;\n",
    "    dataList['expType'] = expType;\n",
    "    np.save(loc_pyData + dl_name, dataList);\n",
    "else: # unitType, isolation, comment must be filled in by hand at later time\n",
    "    dataList = dict();\n",
    "    dataList['unitName'] = unitName;\n",
    "    dataList['unitArea'] = unitArea;\n",
    "    dataList['expType'] = expType;\n",
    "    dataList['expType'] = expType;\n",
    "    dataList['isolation'] = [];\n",
    "    dataList['comment'] = [];\n",
    "    np.save(loc_pyData + dl_name, dataList);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the saved/updated data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = np.load(loc_pyData + dl_name).item();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_6 = hf.np_smart_load(loc_pyData + dataList['unitName'][1] + '_sfm.npy')\n",
    "gt_7 = hf.np_smart_load(loc_pyData + dataList['unitName'][3] + '_sfm.npy')\n",
    "test = hf.np_smart_load(loc_pyData + dataList['unitName'][2] + '_sfm.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5.5, 7. , 5.5, 4.5, 6.5, 7. , 5. , 4.5, 5.5, 5.5]),\n",
       " array([4., 7., 4., 2., 6., 7., 3., 2., 4., 4.]),\n",
       " array([4., 7., 4., 2., 6., 7., 3., 2., 4., 4.])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['sfm']['exp']['trial']['tf'][0][500:510] for x in [gt_6, gt_7, test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676l01_glx182',\n",
       " 'm676p3l06_154',\n",
       " 'm676p3l06_glx_170',\n",
       " 'm676p3l07_154',\n",
       " 'm676p3l07_glx',\n",
       " 'm676p3l13',\n",
       " 'm676p3l15_glx',\n",
       " 'm678p5l06_glx170',\n",
       " 'm678p5l06_glx174',\n",
       " 'm678p5l07_glx',\n",
       " 'm678p6l11_glx',\n",
       " 'm678p6l12_glx',\n",
       " 'm678p6l15_glx41',\n",
       " 'm678p6l16_glx',\n",
       " 'm678p6l18_glx55',\n",
       " 'm678p7r03_glx']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList['unitName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other changes\n",
    "Likely not needed, this section was from converting the previous data set where normalization responses where already computed in Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change some things around...\n",
    "for i in dataList['unitName']:\n",
    "\n",
    "    print(\"changing: \" + i)\n",
    "    S = np.load(loc_pyData + i + '_sfm.npy').item(); # the actual data structure\n",
    "    \n",
    "    if S.get('sfm').get('mod'):\n",
    "        if S.get('sfm').get('mod').get('normalization') and S.get('sfm').get('mod').get('normalization_py'):\n",
    "            \n",
    "            S['sfm']['mod']['norm_old'] = S['sfm']['mod']['normalization'];\n",
    "            S['sfm']['mod']['normalization'] = S['sfm']['mod']['normalization_py'];\n",
    "            S['sfm']['mod'].pop('normalization_py');\n",
    "            \n",
    "            print(\"now saving...\")\n",
    "            saveName = loc_pyData + i + '_sfm.npy';\n",
    "            np.save(saveName, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General 'update python structs' here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this section to update something about each cell in the dataList (change appropriate field(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of analysis in sandbox_careful.ipynb, I've determined that the F1 calculation is in correct, as provided in the matlab files which we use to load the expo XML files. Thus, the 'f1' field associated with each cell has a value which is usually half the true F1 power. Why? Given the nature of the spike train as a real signal, the power at non-DC, positive-frequencies should be doubled from what is calculated in the FFT (see sandbox_careful.ipynb and helper_fcns.py/spike_fft for more details).\n",
    "\n",
    "Below, I'll use this template to load each cell, move the 'f1' field to 'expo_f1', and create a new 'f1' field with the correct calculation.\n",
    "\n",
    "**NOTE:** Now that this move has been completed, do not run the line below \"now let's move the 'f1' field\", since you will then overwrite the original expo F1 calculation ('f1_expo') with our own calculation (now stored in 'f1')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expDirs = ['V1_orig/', 'altExp/', 'V1/']\n",
    "expNames = ['dataList.npy', 'dataList.npy', 'dataList_glx.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: V1_orig/\n",
      "dir: altExp/\n",
      "dir: V1/\n"
     ]
    }
   ],
   "source": [
    "for expDir, dL_nm in zip(expDirs, expNames):\n",
    "\n",
    "    data_loc = base_loc + expDir + 'structures/';\n",
    "    dataList = hf.np_smart_load(data_loc + dL_nm);\n",
    "\n",
    "    print('dir: %s' % expDir)\n",
    "    \n",
    "    # Now, go through for each cell in the dataList                                                                                                                                                                                                                           \n",
    "    nCells = len(dataList['unitName']);\n",
    "    for cell_ind in range(nCells):\n",
    "\n",
    "        # get experiment name, load cell                                                                                                                                                                                                                                        \n",
    "        expName = dataList['unitName'][cell_ind];\n",
    "        expInd = hf.get_exp_ind(data_loc, expName)[0];\n",
    "        cell = hf.np_smart_load(data_loc + expName + '_sfm.npy');\n",
    "        tr_inf = cell['sfm']['exp']['trial']\n",
    "        \n",
    "        # now, let's \"move\" the 'f1' field\n",
    "#         cell['sfm']['exp']['trial']['f1_expo'] = cell['sfm']['exp']['trial']['f1'];\n",
    "        # the real stuff: get the correct f1 calculation\n",
    "        nTrials = len(tr_inf['num']);\n",
    "        stimDur = hf.get_exp_params(expInd, forceDir=expDir).stimDur;\n",
    "        spike_times = [tr_inf['spikeTimes'][x] for x in range(nTrials)]; \n",
    "        psth, bins = hf.make_psth(spike_times, stimDur=stimDur);\n",
    "        n_trs = len(tr_inf['num']);\n",
    "        try: # V1_orig does not have num_comps, but we cannot properly do f1 by component for mixtures with V1_orig (nor altExp)\n",
    "            n_comps = tr_inf['num_comps']\n",
    "            all_tf = [[tr_inf['tf'][c_i][i] for c_i in range(x)] for i, x in enumerate(n_comps)];\n",
    "        except: # so in that case, just get the first grating from each trial\n",
    "            all_tf = tr_inf['tf'][0]; # just take first grating???\n",
    "        power, rel_power, full_ft = hf.spike_fft(psth, tfs=all_tf, stimDur=stimDur);\n",
    "    \n",
    "        cell['sfm']['exp']['trial']['f1'] = rel_power;\n",
    "        \n",
    "        # then save the update!\n",
    "        np.save(data_loc + expName + '_sfm.npy', cell);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed (19.05.12) some cells were not fitting/plotting, due to error in summing total_con it turns out that was caused by *con.shape = (nComps, nTrials) rather than (nComps, ); here, we fix that issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL = np.load(loc_pyData + 'dataList.npy').item();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dL['unitName']:\n",
    "    S = hf.np_smart_load(loc_pyData + i + '_sfm.npy');\n",
    "        \n",
    "    trial = S['sfm']['exp']['trial'];\n",
    "    cons = trial['con'];\n",
    "\n",
    "    if len(cons.shape) == 2:\n",
    "        print('ha! issue with %s' % i);\n",
    "        nComps = cons.shape[0];\n",
    "        newCons = np.zeros((nComps, ), dtype='O')\n",
    "        # for each component, pack as array, which is the default/working method\n",
    "        for ci in range(nComps):\n",
    "            newCons[ci] = np.array(cons[ci, :])\n",
    "        \n",
    "        S['sfm']['exp']['trial']['con'] = newCons;\n",
    "        np.save(loc_pyData + i + '_sfm.npy', S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
