{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting matlab data into python\n",
    "\n",
    "Last update (ymd): 19.08.22  \n",
    "Last access (ymd): 19.08.22  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this Jupyter notebook to convert Expo data from .mat to .npy files, and to make adjustments to existing .npy files (e.g. renaming fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, os\n",
    "import sys\n",
    "sys.path.insert(0, 'functions/'); # add this path for makeStimulus\n",
    "import makeStimulus\n",
    "import helper_fcns as hf\n",
    "import autoreload\n",
    "\n",
    "import pdb\n",
    "\n",
    "# constants - directories\n",
    "base_loc = '/arc/2.2/p1/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/';\n",
    "# base_loc = '/users/plevy/SF_diversity/sfDiv-OriModel/sfDiv-python/';\n",
    "\n",
    "loc_matData = 'V1_orig/structures/'; # where are the .mat files?\n",
    "loc_pyData = 'V1_orig/structures/'; # where do you want the .npy files?\n",
    "\n",
    "recArea = 'V1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The original conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the .mat files to convert; then, convert unless already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(loc_matData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataList.npy',\n",
       " 'dataList_glx.npy',\n",
       " 'dataList_glx_170.npy',\n",
       " 'descrFits_poiss_sach.npy',\n",
       " 'fitList_190131c_flat_chiSq.npy',\n",
       " 'fitList_190131c_wght_chiSq.npy',\n",
       " 'fitList_190202c_flat_chiSq.npy',\n",
       " 'fitList_190202c_wght_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq_details.npy',\n",
       " 'fitList_190206c_wght_chiSq.npy',\n",
       " 'fitList_190206c_wght_chiSq_details.npy',\n",
       " 'fitList_190226c_flat_chiSq.npy',\n",
       " 'fitList_190226c_flat_chiSq_details.npy',\n",
       " 'fitList_190226c_wght_chiSq.npy',\n",
       " 'fitList_190226c_wght_chiSq_details.npy',\n",
       " 'fitList_190301c_flat_chiSq.npy',\n",
       " 'fitList_190301c_flat_chiSq_details.npy',\n",
       " 'fitList_190301c_wght_chiSq.npy',\n",
       " 'fitList_190301c_wght_chiSq_details.npy',\n",
       " 'fitList_190315c_flat_chiSq.npy',\n",
       " 'fitList_190315c_flat_chiSq_details.npy',\n",
       " 'fitList_190315c_wght_chiSq.npy',\n",
       " 'fitList_190315c_wght_chiSq_details.npy',\n",
       " 'fitList_190321c_flat_chiSq.npy',\n",
       " 'fitList_190321c_flat_chiSq_details.npy',\n",
       " 'fitList_190321c_wght_chiSq.npy',\n",
       " 'fitList_190321c_wght_chiSq_details.npy',\n",
       " 'fitList_190409cA_flat_chiSq.npy',\n",
       " 'fitList_190409cA_flat_chiSq_details.npy',\n",
       " 'fitList_190409cA_wght_chiSq.npy',\n",
       " 'fitList_190409cA_wght_chiSq_details.npy',\n",
       " 'fitList_190409cB_flat_chiSq.npy',\n",
       " 'fitList_190409cB_flat_chiSq_details.npy',\n",
       " 'fitList_190409cB_wght_chiSq.npy',\n",
       " 'fitList_190409cB_wght_chiSq_details.npy',\n",
       " 'fitList_190426cA_glx_170_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_170_wght_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_wght_chiSq.npy',\n",
       " 'fitList_190428cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190428cA_glx_wght_chiSq.npy',\n",
       " 'm676l01_sfm.mat',\n",
       " 'm676l01_sfm.npy',\n",
       " 'm676p3l06_glx_170_sfm.mat',\n",
       " 'm676p3l06_glx_170_sfm.npy',\n",
       " 'm676p3l06_glx_sfm.mat',\n",
       " 'm676p3l06_glx_sfm.npy',\n",
       " 'm676p3l06_sfm.mat',\n",
       " 'm676p3l06_sfm.npy',\n",
       " 'm676p3l07_glx_sfm.mat',\n",
       " 'm676p3l07_glx_sfm.npy',\n",
       " 'm676p3l07_sfm.mat',\n",
       " 'm676p3l07_sfm.npy',\n",
       " 'm676p3l13_sfm.mat',\n",
       " 'm676p3l13_sfm.npy',\n",
       " 'm676p3l15_glx_sfm.mat',\n",
       " 'm676p3l15_sfm.mat',\n",
       " 'm676p3l15_sfm.npy',\n",
       " 'm678p5l06_sfm.mat',\n",
       " 'm678p5l06_sfm.npy',\n",
       " 'm678p5l07_sfm.mat',\n",
       " 'm678p5l07_sfm.npy',\n",
       " 'm678p6l11_sfm.mat',\n",
       " 'm678p6l11_sfm.npy',\n",
       " 'm678p6l12_sfm.mat',\n",
       " 'm678p6l12_sfm.npy',\n",
       " 'm678p6l15_sfm.mat',\n",
       " 'm678p6l15_sfm.npy',\n",
       " 'm678p6l16_sfm.mat',\n",
       " 'm678p6l16_sfm.npy',\n",
       " 'm678p6l18_sfm.mat',\n",
       " 'm678p6l18_sfm.npy',\n",
       " 'm678p7r03_sfm.mat',\n",
       " 'm678p7r03_sfm.npy',\n",
       " 'phaseAdvanceFitsTest_neg.npy',\n",
       " 'phaseAdvanceFitsTest_pos.npy',\n",
       " 'rvcFitsTest_neg.npy',\n",
       " 'rvcFitsTest_pos.npy',\n",
       " 'rvcFits_pos.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "#     if i.find('#') >= 0:\n",
    "#         os.rename(loc_matData + i, loc_matData + i.replace('#', ''))\n",
    "#         print('IGNORE: renaming %s to %s' % (loc_matData + i, loc_matData + i.replace('#', '')))\n",
    "    if i.find('m678') >=0 and i.find('.mat') >= 0: # or change to .xml/.exxd if changing names in /recordings\n",
    "        r_ind = i.find('r');\n",
    "        if r_ind < 0:\n",
    "            r_ind = i.find('l')\n",
    "            \n",
    "#         rEnd_ind = i.find('#') # if changing in /recordings/\n",
    "        rEnd_ind = i.find('_') # if changing in /structures/\n",
    "        substr_to_replace = i[r_ind+1:rEnd_ind]\n",
    "#         print('substr: %s' % substr_to_replace)\n",
    "        new_str = i[0:r_ind+1] + '%02d' % int(substr_to_replace) + i[rEnd_ind:]\n",
    "        if new_str == i:\n",
    "            continue;\n",
    "#         os.rename(loc_matData + i, loc_matData + new_str)\n",
    "        print('renaming %s to %s' % (loc_matData + i, loc_matData + new_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(loc_matData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataList.npy',\n",
       " 'dataList_glx.npy',\n",
       " 'dataList_glx_170.npy',\n",
       " 'descrFits_poiss_sach.npy',\n",
       " 'fitList_190131c_flat_chiSq.npy',\n",
       " 'fitList_190131c_wght_chiSq.npy',\n",
       " 'fitList_190202c_flat_chiSq.npy',\n",
       " 'fitList_190202c_wght_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq.npy',\n",
       " 'fitList_190206c_flat_chiSq_details.npy',\n",
       " 'fitList_190206c_wght_chiSq.npy',\n",
       " 'fitList_190206c_wght_chiSq_details.npy',\n",
       " 'fitList_190226c_flat_chiSq.npy',\n",
       " 'fitList_190226c_flat_chiSq_details.npy',\n",
       " 'fitList_190226c_wght_chiSq.npy',\n",
       " 'fitList_190226c_wght_chiSq_details.npy',\n",
       " 'fitList_190301c_flat_chiSq.npy',\n",
       " 'fitList_190301c_flat_chiSq_details.npy',\n",
       " 'fitList_190301c_wght_chiSq.npy',\n",
       " 'fitList_190301c_wght_chiSq_details.npy',\n",
       " 'fitList_190315c_flat_chiSq.npy',\n",
       " 'fitList_190315c_flat_chiSq_details.npy',\n",
       " 'fitList_190315c_wght_chiSq.npy',\n",
       " 'fitList_190315c_wght_chiSq_details.npy',\n",
       " 'fitList_190321c_flat_chiSq.npy',\n",
       " 'fitList_190321c_flat_chiSq_details.npy',\n",
       " 'fitList_190321c_wght_chiSq.npy',\n",
       " 'fitList_190321c_wght_chiSq_details.npy',\n",
       " 'fitList_190409cA_flat_chiSq.npy',\n",
       " 'fitList_190409cA_flat_chiSq_details.npy',\n",
       " 'fitList_190409cA_wght_chiSq.npy',\n",
       " 'fitList_190409cA_wght_chiSq_details.npy',\n",
       " 'fitList_190409cB_flat_chiSq.npy',\n",
       " 'fitList_190409cB_flat_chiSq_details.npy',\n",
       " 'fitList_190409cB_wght_chiSq.npy',\n",
       " 'fitList_190409cB_wght_chiSq_details.npy',\n",
       " 'fitList_190426cA_glx_170_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_170_wght_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_flat_chiSq.npy',\n",
       " 'fitList_190426cA_glx_180_wght_chiSq.npy',\n",
       " 'fitList_190428cA_glx_flat_chiSq.npy',\n",
       " 'fitList_190428cA_glx_wght_chiSq.npy',\n",
       " 'm676l01_sfm.mat',\n",
       " 'm676l01_sfm.npy',\n",
       " 'm676p3l06_glx_170_sfm.mat',\n",
       " 'm676p3l06_glx_170_sfm.npy',\n",
       " 'm676p3l06_glx_sfm.mat',\n",
       " 'm676p3l06_glx_sfm.npy',\n",
       " 'm676p3l06_sfm.mat',\n",
       " 'm676p3l06_sfm.npy',\n",
       " 'm676p3l07_glx_sfm.mat',\n",
       " 'm676p3l07_glx_sfm.npy',\n",
       " 'm676p3l07_sfm.mat',\n",
       " 'm676p3l07_sfm.npy',\n",
       " 'm676p3l13_sfm.mat',\n",
       " 'm676p3l13_sfm.npy',\n",
       " 'm676p3l15_glx_sfm.mat',\n",
       " 'm676p3l15_sfm.mat',\n",
       " 'm676p3l15_sfm.npy',\n",
       " 'm678p5l06_sfm.mat',\n",
       " 'm678p5l06_sfm.npy',\n",
       " 'm678p5l07_sfm.mat',\n",
       " 'm678p5l07_sfm.npy',\n",
       " 'm678p6l11_sfm.mat',\n",
       " 'm678p6l11_sfm.npy',\n",
       " 'm678p6l12_sfm.mat',\n",
       " 'm678p6l12_sfm.npy',\n",
       " 'm678p6l15_sfm.mat',\n",
       " 'm678p6l15_sfm.npy',\n",
       " 'm678p6l16_sfm.mat',\n",
       " 'm678p6l16_sfm.npy',\n",
       " 'm678p6l18_sfm.mat',\n",
       " 'm678p6l18_sfm.npy',\n",
       " 'm678p7r03_sfm.mat',\n",
       " 'm678p7r03_sfm.npy',\n",
       " 'phaseAdvanceFitsTest_neg.npy',\n",
       " 'phaseAdvanceFitsTest_pos.npy',\n",
       " 'rvcFitsTest_neg.npy',\n",
       " 'rvcFitsTest_pos.npy',\n",
       " 'rvcFits_pos.npy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: m676p3l15_glx_sfm.mat\n",
      "now saving...\n"
     ]
    }
   ],
   "source": [
    "# convert individual files\n",
    "unitName = [];\n",
    "expType  = [];\n",
    "unitArea = [];\n",
    "for i in files:\n",
    "    # if file has 'sfm' in it and starts with m then \n",
    "    if i.find('sfm') >= 0 and i.startswith('m'):\n",
    "        \n",
    "        # don't convert if it already exists\n",
    "        if os.path.exists(loc_pyData + i.replace('.mat', '.npy')):\n",
    "            if i.endswith('.npy') and i.find('fullWave') == -1: # only add once (not also with .mat)\n",
    "                unitName.append(i[0:i.find('_')]) # go up to the '_' character\n",
    "                _, expName = hf.get_exp_ind(loc_pyData, i[0:i.find('_')])\n",
    "                if expName is None:\n",
    "                    pdb.set_trace();\n",
    "                expType.append(expName);\n",
    "                unitArea.append(recArea)\n",
    "            continue;\n",
    "                \n",
    "        print(\"loading: \" + i)\n",
    "        matData = makeStimulus.loadmat(loc_matData + i);\n",
    "        S = matData.get('S'); # the actual data structure\n",
    "        _, expName = hf.get_exp_ind(loc_pyData, i[0:i.find('_')])\n",
    "        \n",
    "        print(\"now saving...\")\n",
    "        saveName = loc_pyData + i.replace('.mat', '.npy');\n",
    "        np.save(saveName, S)\n",
    "        \n",
    "        unitName.append(i[0:i.find('_')]) # go up to the '_' character\n",
    "        expType.append(expName);\n",
    "        unitArea.append(recArea);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix',\n",
       " 'sfMix']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1',\n",
       " 'V1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m676l01',\n",
       " 'm676p3l06',\n",
       " 'm676p3l07',\n",
       " 'm676p3l13',\n",
       " 'm676p3l15',\n",
       " 'm678p5l06',\n",
       " 'm678p5l07',\n",
       " 'm678p6l11',\n",
       " 'm678p6l12',\n",
       " 'm678p6l15',\n",
       " 'm678p6l16',\n",
       " 'm678p6l18',\n",
       " 'm678p7r03']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create/update data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(loc_pyData + 'dataList.npy'):\n",
    "    dataList = np.load(loc_pyData + 'dataList.npy').item();\n",
    "    dataList['unitName'] = unitName;\n",
    "    dataList['unitArea'] = unitArea;\n",
    "    dataList['expType'] = expType;\n",
    "    np.save(loc_pyData + 'dataList.npy', dataList);\n",
    "else: # unitType, isolation, comment must be filled in by hand at later time\n",
    "    dataList = dict();\n",
    "    dataList['unitName'] = unitName;\n",
    "    dataList['unitArea'] = unitArea;\n",
    "    dataList['expType'] = expType;\n",
    "    dataList['expType'] = expType;\n",
    "    dataList['isolation'] = [];\n",
    "    dataList['comment'] = [];\n",
    "    np.save(loc_pyData + 'dataList.npy', dataList);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the saved/updated data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = np.load(loc_pyData + 'dataList.npy').item();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likely not needed, this section was from converting the previous data set where normalization responses where already computed in Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change some things around...\n",
    "for i in dataList['unitName']:\n",
    "\n",
    "    print(\"changing: \" + i)\n",
    "    S = np.load(loc_pyData + i + '_sfm.npy').item(); # the actual data structure\n",
    "    \n",
    "    if S.get('sfm').get('mod'):\n",
    "        if S.get('sfm').get('mod').get('normalization') and S.get('sfm').get('mod').get('normalization_py'):\n",
    "            \n",
    "            S['sfm']['mod']['norm_old'] = S['sfm']['mod']['normalization'];\n",
    "            S['sfm']['mod']['normalization'] = S['sfm']['mod']['normalization_py'];\n",
    "            S['sfm']['mod'].pop('normalization_py');\n",
    "            \n",
    "            print(\"now saving...\")\n",
    "            saveName = loc_pyData + i + '_sfm.npy';\n",
    "            np.save(saveName, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General 'update python structs' here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this section to update something about each cell in the dataList (change appropriate field(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of analysis in sandbox_careful.ipynb, I've determined that the F1 calculation is in correct, as provided in the matlab files which we use to load the expo XML files. Thus, the 'f1' field associated with each cell has a value which is usually half the true F1 power. Why? Given the nature of the spike train as a real signal, the power at non-DC, positive-frequencies should be doubled from what is calculated in the FFT (see sandbox_careful.ipynb and helper_fcns.py/spike_fft for more details).\n",
    "\n",
    "Below, I'll use this template to load each cell, move the 'f1' field to 'expo_f1', and create a new 'f1' field with the correct calculation.\n",
    "\n",
    "**NOTE:** Now that this move has been completed, do not run the line below \"now let's move the 'f1' field\", since you will then overwrite the original expo F1 calculation ('f1_expo') with our own calculation (now stored in 'f1')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "expDirs = ['V1_orig/', 'altExp/', 'V1/']\n",
    "expNames = ['dataList.npy', 'dataList.npy', 'dataList_glx.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: V1_orig/\n",
      "dir: altExp/\n",
      "dir: V1/\n"
     ]
    }
   ],
   "source": [
    "for expDir, dL_nm in zip(expDirs, expNames):\n",
    "\n",
    "    data_loc = base_loc + expDir + 'structures/';\n",
    "    dataList = hf.np_smart_load(data_loc + dL_nm);\n",
    "\n",
    "    print('dir: %s' % expDir)\n",
    "    \n",
    "    # Now, go through for each cell in the dataList                                                                                                                                                                                                                           \n",
    "    nCells = len(dataList['unitName']);\n",
    "    for cell_ind in range(nCells):\n",
    "\n",
    "        # get experiment name, load cell                                                                                                                                                                                                                                        \n",
    "        expName = dataList['unitName'][cell_ind];\n",
    "        expInd = hf.get_exp_ind(data_loc, expName)[0];\n",
    "        cell = hf.np_smart_load(data_loc + expName + '_sfm.npy');\n",
    "        tr_inf = cell['sfm']['exp']['trial']\n",
    "        \n",
    "        # now, let's \"move\" the 'f1' field\n",
    "#         cell['sfm']['exp']['trial']['f1_expo'] = cell['sfm']['exp']['trial']['f1'];\n",
    "        # the real stuff: get the correct f1 calculation\n",
    "        nTrials = len(tr_inf['num']);\n",
    "        stimDur = hf.get_exp_params(expInd, forceDir=expDir).stimDur;\n",
    "        spike_times = [tr_inf['spikeTimes'][x] for x in range(nTrials)]; \n",
    "        psth, bins = hf.make_psth(spike_times, stimDur=stimDur);\n",
    "        all_tf = tr_inf['tf'][0]; # just take first grating???\n",
    "        power, rel_power, full_ft = hf.spike_fft(psth, tfs=all_tf, stimDur=stimDur);\n",
    "    \n",
    "        cell['sfm']['exp']['trial']['f1'] = rel_power;\n",
    "        \n",
    "        # then save the update!\n",
    "        np.save(data_loc + expName + '_sfm.npy', cell);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed (19.05.12) some cells were not fitting/plotting, due to error in summing total_con it turns out that was caused by *con.shape = (nComps, nTrials) rather than (nComps, ); here, we fix that issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL = np.load(loc_pyData + 'dataList.npy').item();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha! issue with m660r04\n",
      "ha! issue with m660r22\n"
     ]
    }
   ],
   "source": [
    "for i in dL['unitName']:\n",
    "    S = hf.np_smart_load(loc_pyData + i + '_sfm.npy');\n",
    "        \n",
    "    trial = S['sfm']['exp']['trial'];\n",
    "    cons = trial['con'];\n",
    "\n",
    "    if len(cons.shape) == 2:\n",
    "        print('ha! issue with %s' % i);\n",
    "        nComps = cons.shape[0];\n",
    "        newCons = np.zeros((nComps, ), dtype='O')\n",
    "        # for each component, pack as array, which is the default/working method\n",
    "        for ci in range(nComps):\n",
    "            newCons[ci] = np.array(cons[ci, :])\n",
    "        \n",
    "        S['sfm']['exp']['trial']['con'] = newCons;\n",
    "        np.save(loc_pyData + i + '_sfm.npy', S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
